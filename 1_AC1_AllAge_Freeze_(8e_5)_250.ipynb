{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/run/blob/main/1_AC1_AllAge_Freeze_(8e_5)_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow7eWoNw6U-c"
      },
      "source": [
        "#เรียกใช้ CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1_2Fe8u81d5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abfd55a-22cc-41cd-b3cb-14f876f4f930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6eae5e86-10fa-43b8-976b-8d9753fda9a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7   Y07         0         V1.jpg   \n",
              "1           2               1          7   Y07         0    Flip_V1.jpg   \n",
              "2           3               2          7   Y07         0         V2.jpg   \n",
              "3           4               2          7   Y07         0    Flip_V2.jpg   \n",
              "4           5               3          7   Y07         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25   Y25        18  Flip_J463.jpg   \n",
              "4746      122              78         25   Y25        18       J464.jpg   \n",
              "4747      123              78         25   Y25        18  Flip_J464.jpg   \n",
              "4748      124              79         25   Y25        18       J465.jpg   \n",
              "4749      125              79         25   Y25        18  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_All_Age/train/Y07/...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_All_Age/test/Y25/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_All_Age/test/Y25/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_All_Age/test/Y25/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_All_Age/test/Y25/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_All_Age/test/Y25/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b9a8ef9-c82a-498d-925e-f28f80c202c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/train/Y07/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25</td>\n",
              "      <td>18</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_All_Age/test/Y25/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b9a8ef9-c82a-498d-925e-f28f80c202c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b9a8ef9-c82a-498d-925e-f28f80c202c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b9a8ef9-c82a-498d-925e-f28f80c202c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_All_Age_0.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxePnnn7TGW"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RooqSdBc7QHC"
      },
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pumGmy6f3eSW"
      },
      "source": [
        "#Clone efficientnet repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "2041f2f1-8b0a-438b-de91-43110aebe6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ],
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "outputs": [],
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uhCmH24AKmQ4"
      },
      "outputs": [],
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(19, activation='softmax', name=\"fc_out\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NadBB12251jh",
        "outputId": "14c4e7a9-b676-42af-aac1-307917c8c302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 4,031,887\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GepWq3yy53t5",
        "outputId": "583a4001-719e-49ad-c4b1-102de3f62dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIWHby0gKpEq",
        "outputId": "4a3955c7-4a78-4a39-8ab9-aa0dd27e0bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 75, 75, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 75, 75, 32)  128         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_49 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 75, 75, 32)  288         ['swish_49[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 75, 75, 32)  128         ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_50 (Swish)               (None, 75, 75, 32)   0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_16 (Lambda)             (None, 1, 1, 32)     0           ['swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 1, 1, 8)      264         ['lambda_16[0][0]']              \n",
            "                                                                                                  \n",
            " swish_51 (Swish)               (None, 1, 1, 8)      0           ['conv2d_66[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 1, 1, 32)     288         ['swish_51[0][0]']               \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 1, 1, 32)     0           ['conv2d_67[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_16 (Multiply)         (None, 75, 75, 32)   0           ['activation_16[0][0]',          \n",
            "                                                                  'swish_50[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 75, 75, 16)   512         ['multiply_16[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 75, 75, 16)  64          ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 75, 75, 96)   1536        ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 75, 75, 96)  384         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_52 (Swish)               (None, 75, 75, 96)   0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 38, 38, 96)  864         ['swish_52[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 38, 38, 96)  384         ['depthwise_conv2d_17[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_53 (Swish)               (None, 38, 38, 96)   0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_17 (Lambda)             (None, 1, 1, 96)     0           ['swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 1, 1, 4)      388         ['lambda_17[0][0]']              \n",
            "                                                                                                  \n",
            " swish_54 (Swish)               (None, 1, 1, 4)      0           ['conv2d_70[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 1, 1, 96)     480         ['swish_54[0][0]']               \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 1, 1, 96)     0           ['conv2d_71[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_17 (Multiply)         (None, 38, 38, 96)   0           ['activation_17[0][0]',          \n",
            "                                                                  'swish_53[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 38, 38, 24)   2304        ['multiply_17[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 38, 38, 24)  96          ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 38, 38, 144)  3456        ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 38, 38, 144)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_55 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 38, 38, 144)  1296       ['swish_55[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 38, 38, 144)  576        ['depthwise_conv2d_18[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_56 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_18 (Lambda)             (None, 1, 1, 144)    0           ['swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_18[0][0]']              \n",
            "                                                                                                  \n",
            " swish_57 (Swish)               (None, 1, 1, 6)      0           ['conv2d_74[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_57[0][0]']               \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 1, 1, 144)    0           ['conv2d_75[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)         (None, 38, 38, 144)  0           ['activation_18[0][0]',          \n",
            "                                                                  'swish_56[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_18[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 38, 38, 24)  96          ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_9 (DropConnect)   (None, 38, 38, 24)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 38, 38, 24)   0           ['drop_connect_9[0][0]',         \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 38, 38, 144)  3456        ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 38, 38, 144)  576        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_58 (Swish)               (None, 38, 38, 144)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 19, 19, 144)  3600       ['swish_58[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_19[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_59 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_19 (Lambda)             (None, 1, 1, 144)    0           ['swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_19[0][0]']              \n",
            "                                                                                                  \n",
            " swish_60 (Swish)               (None, 1, 1, 6)      0           ['conv2d_78[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_60[0][0]']               \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 1, 1, 144)    0           ['conv2d_79[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)         (None, 19, 19, 144)  0           ['activation_19[0][0]',          \n",
            "                                                                  'swish_59[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_19[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 19, 19, 40)  160         ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 19, 19, 240)  960        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_61 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 19, 19, 240)  6000       ['swish_61[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_20[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_62 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_20 (Lambda)             (None, 1, 1, 240)    0           ['swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_20[0][0]']              \n",
            "                                                                                                  \n",
            " swish_63 (Swish)               (None, 1, 1, 10)     0           ['conv2d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_63[0][0]']               \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 1, 1, 240)    0           ['conv2d_83[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_20 (Multiply)         (None, 19, 19, 240)  0           ['activation_20[0][0]',          \n",
            "                                                                  'swish_62[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_20[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 19, 19, 40)  160         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_10 (DropConnect)  (None, 19, 19, 40)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 19, 19, 40)   0           ['drop_connect_10[0][0]',        \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 19, 19, 240)  9600        ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 19, 19, 240)  960        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_64 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 10, 10, 240)  2160       ['swish_64[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_21[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_65 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_21 (Lambda)             (None, 1, 1, 240)    0           ['swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_21[0][0]']              \n",
            "                                                                                                  \n",
            " swish_66 (Swish)               (None, 1, 1, 10)     0           ['conv2d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_66[0][0]']               \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 1, 1, 240)    0           ['conv2d_87[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_21 (Multiply)         (None, 10, 10, 240)  0           ['activation_21[0][0]',          \n",
            "                                                                  'swish_65[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_21[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 10, 10, 80)  320         ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_67 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 10, 10, 480)  4320       ['swish_67[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_22[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_68 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_22 (Lambda)             (None, 1, 1, 480)    0           ['swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_22[0][0]']              \n",
            "                                                                                                  \n",
            " swish_69 (Swish)               (None, 1, 1, 20)     0           ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_69[0][0]']               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 1, 1, 480)    0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_22 (Multiply)         (None, 10, 10, 480)  0           ['activation_22[0][0]',          \n",
            "                                                                  'swish_68[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 10, 10, 80)  320         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_11 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_11[0][0]',        \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 10, 10, 480)  38400       ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_70 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 10, 10, 480)  4320       ['swish_70[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_23[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_71 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_23 (Lambda)             (None, 1, 1, 480)    0           ['swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_23[0][0]']              \n",
            "                                                                                                  \n",
            " swish_72 (Swish)               (None, 1, 1, 20)     0           ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_72[0][0]']               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 1, 1, 480)    0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_23 (Multiply)         (None, 10, 10, 480)  0           ['activation_23[0][0]',          \n",
            "                                                                  'swish_71[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_23[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 10, 10, 80)  320         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_12 (DropConnect)  (None, 10, 10, 80)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 10, 10, 80)   0           ['drop_connect_12[0][0]',        \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 10, 10, 480)  38400       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_73 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_24 (Depthwise  (None, 10, 10, 480)  12000      ['swish_73[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_24[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_74 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_24 (Lambda)             (None, 1, 1, 480)    0           ['swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_24[0][0]']              \n",
            "                                                                                                  \n",
            " swish_75 (Swish)               (None, 1, 1, 20)     0           ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_75[0][0]']               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 1, 1, 480)    0           ['conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_24 (Multiply)         (None, 10, 10, 480)  0           ['activation_24[0][0]',          \n",
            "                                                                  'swish_74[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 10, 10, 112)  53760       ['multiply_24[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 10, 10, 112)  448        ['conv2d_100[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 10, 10, 672)  75264       ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_76 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_25 (Depthwise  (None, 10, 10, 672)  16800      ['swish_76[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_25[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_77 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_25 (Lambda)             (None, 1, 1, 672)    0           ['swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_25[0][0]']              \n",
            "                                                                                                  \n",
            " swish_78 (Swish)               (None, 1, 1, 28)     0           ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_78[0][0]']               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 1, 1, 672)    0           ['conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 10, 10, 672)  0           ['activation_25[0][0]',          \n",
            "                                                                  'swish_77[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 10, 10, 112)  448        ['conv2d_104[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_13 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_13[0][0]',        \n",
            "                                                                  'batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 10, 10, 672)  75264       ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_79 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_26 (Depthwise  (None, 10, 10, 672)  16800      ['swish_79[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_26[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_80 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_26 (Lambda)             (None, 1, 1, 672)    0           ['swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_26[0][0]']              \n",
            "                                                                                                  \n",
            " swish_81 (Swish)               (None, 1, 1, 28)     0           ['conv2d_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_81[0][0]']               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 672)    0           ['conv2d_107[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 10, 10, 672)  0           ['activation_26[0][0]',          \n",
            "                                                                  'swish_80[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 10, 10, 112)  75264       ['multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 10, 10, 112)  448        ['conv2d_108[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_14 (DropConnect)  (None, 10, 10, 112)  0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 10, 10, 112)  0           ['drop_connect_14[0][0]',        \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 10, 10, 672)  75264       ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_82 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_27 (Depthwise  (None, 5, 5, 672)   16800       ['swish_82[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_27[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_83 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_27 (Lambda)             (None, 1, 1, 672)    0           ['swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 1, 1, 28)     18844       ['lambda_27[0][0]']              \n",
            "                                                                                                  \n",
            " swish_84 (Swish)               (None, 1, 1, 28)     0           ['conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 1, 1, 672)    19488       ['swish_84[0][0]']               \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 672)    0           ['conv2d_111[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 5, 5, 672)    0           ['activation_27[0][0]',          \n",
            "                                                                  'swish_83[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 5, 5, 192)    129024      ['multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   768         ['conv2d_112[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 5, 5, 1152)   221184      ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_85 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_28 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_85[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_28[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_86 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_28 (Lambda)             (None, 1, 1, 1152)   0           ['swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_28[0][0]']              \n",
            "                                                                                                  \n",
            " swish_87 (Swish)               (None, 1, 1, 48)     0           ['conv2d_114[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_87[0][0]']               \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_115[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 5, 5, 1152)   0           ['activation_28[0][0]',          \n",
            "                                                                  'swish_86[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 192)   768         ['conv2d_116[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_15 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_15[0][0]',        \n",
            "                                                                  'batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_117[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_88 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_29 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_88[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_29[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_89 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_29 (Lambda)             (None, 1, 1, 1152)   0           ['swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_29[0][0]']              \n",
            "                                                                                                  \n",
            " swish_90 (Swish)               (None, 1, 1, 48)     0           ['conv2d_118[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_90[0][0]']               \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_119[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 5, 5, 1152)   0           ['activation_29[0][0]',          \n",
            "                                                                  'swish_89[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 192)   768         ['conv2d_120[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_16 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_16[0][0]',        \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_121[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_91 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_30 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_91[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_30[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_92 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_30 (Lambda)             (None, 1, 1, 1152)   0           ['swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_30[0][0]']              \n",
            "                                                                                                  \n",
            " swish_93 (Swish)               (None, 1, 1, 48)     0           ['conv2d_122[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_93[0][0]']               \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_123[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)         (None, 5, 5, 1152)   0           ['activation_30[0][0]',          \n",
            "                                                                  'swish_92[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 5, 5, 192)    221184      ['multiply_30[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   768         ['conv2d_124[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_17 (DropConnect)  (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 5, 5, 192)    0           ['drop_connect_17[0][0]',        \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 5, 5, 1152)   221184      ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_125[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_94 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_31 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_94[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_31[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_95 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_31 (Lambda)             (None, 1, 1, 1152)   0           ['swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 1, 1, 48)     55344       ['lambda_31[0][0]']              \n",
            "                                                                                                  \n",
            " swish_96 (Swish)               (None, 1, 1, 48)     0           ['conv2d_126[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 1152)   56448       ['swish_96[0][0]']               \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_127[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)         (None, 5, 5, 1152)   0           ['activation_31[0][0]',          \n",
            "                                                                  'swish_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 5, 5, 320)    368640      ['multiply_31[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_128[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 5, 5, 1280)   409600      ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_129[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_97 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary() #ดู Summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Uj7nbQgSco7g",
        "outputId": "a6f11c30-2db0-4413-9930-379f9c43b7a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 19)                24339     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,073,903\n",
            "Trainable params: 24,339\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J36J9EAE7qSB"
      },
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_All_Age'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWEnlTSwazL5"
      },
      "source": [
        "\n",
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGPrsn9no_pa",
        "outputId": "a8a31108-10da-444b-8217-b0e1f6fba6b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 images belonging to 19 classes.\n",
            "Found 950 images belonging to 19 classes.\n"
          ]
        }
      ],
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6qUmmF856ZE",
        "outputId": "eff9f077-b628-44d2-ca80-28e54a6ad6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-5b290c04e531>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 757s 4s/step - loss: 4.1166 - acc: 0.0558 - val_loss: 3.7001 - val_acc: 0.0657\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 18s 101ms/step - loss: 3.7594 - acc: 0.0748 - val_loss: 3.5360 - val_acc: 0.0689\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.6224 - acc: 0.0889 - val_loss: 3.2936 - val_acc: 0.0911\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 19s 105ms/step - loss: 3.5097 - acc: 0.0896 - val_loss: 3.2128 - val_acc: 0.1038\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.4579 - acc: 0.0974 - val_loss: 3.0693 - val_acc: 0.1186\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 3.3684 - acc: 0.1034 - val_loss: 3.0178 - val_acc: 0.1081\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.3144 - acc: 0.1090 - val_loss: 2.9257 - val_acc: 0.1324\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.2610 - acc: 0.1066 - val_loss: 2.9751 - val_acc: 0.1271\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.2062 - acc: 0.1270 - val_loss: 2.8636 - val_acc: 0.1292\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 3.2042 - acc: 0.1196 - val_loss: 2.7810 - val_acc: 0.1441\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.1370 - acc: 0.1291 - val_loss: 2.8018 - val_acc: 0.1462\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 3.1167 - acc: 0.1288 - val_loss: 2.7891 - val_acc: 0.1483\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.1235 - acc: 0.1228 - val_loss: 2.8018 - val_acc: 0.1578\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 3.0580 - acc: 0.1387 - val_loss: 2.7984 - val_acc: 0.1589\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 3.0619 - acc: 0.1267 - val_loss: 2.7771 - val_acc: 0.1600\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 3.0091 - acc: 0.1302 - val_loss: 2.7934 - val_acc: 0.1504\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.9982 - acc: 0.1415 - val_loss: 2.7258 - val_acc: 0.1515\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.9522 - acc: 0.1588 - val_loss: 2.7218 - val_acc: 0.1621\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.9159 - acc: 0.1461 - val_loss: 2.7310 - val_acc: 0.1536\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.9238 - acc: 0.1454 - val_loss: 2.7685 - val_acc: 0.1653\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.9110 - acc: 0.1429 - val_loss: 2.7514 - val_acc: 0.1621\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.9021 - acc: 0.1411 - val_loss: 2.7775 - val_acc: 0.1600\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.8580 - acc: 0.1514 - val_loss: 2.7520 - val_acc: 0.1578\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8835 - acc: 0.1602 - val_loss: 2.7221 - val_acc: 0.1684\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.8125 - acc: 0.1620 - val_loss: 2.6906 - val_acc: 0.1589\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.7770 - acc: 0.1588 - val_loss: 2.7004 - val_acc: 0.1610\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.8176 - acc: 0.1538 - val_loss: 2.6797 - val_acc: 0.1653\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.7739 - acc: 0.1687 - val_loss: 2.6374 - val_acc: 0.1631\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.7942 - acc: 0.1665 - val_loss: 2.6858 - val_acc: 0.1674\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7713 - acc: 0.1577 - val_loss: 2.6438 - val_acc: 0.1748\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.7552 - acc: 0.1655 - val_loss: 2.6996 - val_acc: 0.1758\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.7368 - acc: 0.1627 - val_loss: 2.6471 - val_acc: 0.1727\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.7256 - acc: 0.1644 - val_loss: 2.6872 - val_acc: 0.1748\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.7585 - acc: 0.1546 - val_loss: 2.6936 - val_acc: 0.1758\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7334 - acc: 0.1616 - val_loss: 2.7340 - val_acc: 0.1600\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.7147 - acc: 0.1598 - val_loss: 2.6630 - val_acc: 0.1780\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 19s 107ms/step - loss: 2.6906 - acc: 0.1687 - val_loss: 2.6979 - val_acc: 0.1769\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.7230 - acc: 0.1627 - val_loss: 2.6727 - val_acc: 0.1843\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6400 - acc: 0.1754 - val_loss: 2.6540 - val_acc: 0.1790\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.7044 - acc: 0.1602 - val_loss: 2.6731 - val_acc: 0.1769\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.6508 - acc: 0.1789 - val_loss: 2.6581 - val_acc: 0.1769\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6159 - acc: 0.1708 - val_loss: 2.6833 - val_acc: 0.1758\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6545 - acc: 0.1680 - val_loss: 2.6968 - val_acc: 0.1727\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6119 - acc: 0.1821 - val_loss: 2.6763 - val_acc: 0.1536\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6469 - acc: 0.1725 - val_loss: 2.6714 - val_acc: 0.1822\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.6327 - acc: 0.1725 - val_loss: 2.6637 - val_acc: 0.1790\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.6052 - acc: 0.1912 - val_loss: 2.6361 - val_acc: 0.1790\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 19s 102ms/step - loss: 2.5844 - acc: 0.1662 - val_loss: 2.6432 - val_acc: 0.1822\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.6195 - acc: 0.1750 - val_loss: 2.6081 - val_acc: 0.1780\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.6230 - acc: 0.1704 - val_loss: 2.6407 - val_acc: 0.1864\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5923 - acc: 0.1733 - val_loss: 2.5984 - val_acc: 0.1864\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5845 - acc: 0.1740 - val_loss: 2.5468 - val_acc: 0.1875\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 2.5786 - acc: 0.1754 - val_loss: 2.6485 - val_acc: 0.1769\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.5672 - acc: 0.1803 - val_loss: 2.6676 - val_acc: 0.1716\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.5328 - acc: 0.1835 - val_loss: 2.6476 - val_acc: 0.1663\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5460 - acc: 0.1860 - val_loss: 2.6063 - val_acc: 0.1875\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5855 - acc: 0.1814 - val_loss: 2.6230 - val_acc: 0.1907\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5646 - acc: 0.1740 - val_loss: 2.6620 - val_acc: 0.1780\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5251 - acc: 0.1845 - val_loss: 2.6768 - val_acc: 0.1695\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.5100 - acc: 0.1928 - val_loss: 2.6541 - val_acc: 0.1610\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.5061 - acc: 0.1980 - val_loss: 2.6484 - val_acc: 0.1790\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.5177 - acc: 0.1987 - val_loss: 2.6978 - val_acc: 0.1695\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.5014 - acc: 0.1860 - val_loss: 2.6916 - val_acc: 0.1748\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.4962 - acc: 0.1870 - val_loss: 2.7322 - val_acc: 0.1811\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.5374 - acc: 0.1722 - val_loss: 2.7067 - val_acc: 0.1748\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 19s 103ms/step - loss: 2.4857 - acc: 0.2040 - val_loss: 2.7099 - val_acc: 0.1833\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4835 - acc: 0.1902 - val_loss: 2.6667 - val_acc: 0.1748\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4927 - acc: 0.1937 - val_loss: 2.6225 - val_acc: 0.1801\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.4765 - acc: 0.1987 - val_loss: 2.6947 - val_acc: 0.1864\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 19s 106ms/step - loss: 2.4797 - acc: 0.1881 - val_loss: 2.7412 - val_acc: 0.1811\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4910 - acc: 0.1874 - val_loss: 2.6681 - val_acc: 0.1822\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.4793 - acc: 0.1845 - val_loss: 2.6871 - val_acc: 0.1790\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.4356 - acc: 0.2036 - val_loss: 2.6708 - val_acc: 0.1843\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4769 - acc: 0.1870 - val_loss: 2.6977 - val_acc: 0.1886\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4557 - acc: 0.1920 - val_loss: 2.6488 - val_acc: 0.1875\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.4797 - acc: 0.1867 - val_loss: 2.6521 - val_acc: 0.1875\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4574 - acc: 0.1962 - val_loss: 2.6479 - val_acc: 0.1843\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4004 - acc: 0.1962 - val_loss: 2.6832 - val_acc: 0.1811\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.4335 - acc: 0.2036 - val_loss: 2.6752 - val_acc: 0.1854\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.4174 - acc: 0.2131 - val_loss: 2.6988 - val_acc: 0.1801\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4510 - acc: 0.1902 - val_loss: 2.6395 - val_acc: 0.1811\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4277 - acc: 0.2015 - val_loss: 2.6639 - val_acc: 0.1833\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4256 - acc: 0.2057 - val_loss: 2.6518 - val_acc: 0.1833\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4081 - acc: 0.2001 - val_loss: 2.6354 - val_acc: 0.1790\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 2.4344 - acc: 0.1980 - val_loss: 2.6571 - val_acc: 0.1864\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.4290 - acc: 0.2092 - val_loss: 2.6633 - val_acc: 0.1886\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4314 - acc: 0.1898 - val_loss: 2.6924 - val_acc: 0.1843\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3801 - acc: 0.2149 - val_loss: 2.7274 - val_acc: 0.1864\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 19s 102ms/step - loss: 2.3990 - acc: 0.1983 - val_loss: 2.6987 - val_acc: 0.1790\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.3871 - acc: 0.2117 - val_loss: 2.6762 - val_acc: 0.1864\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3822 - acc: 0.2107 - val_loss: 2.6628 - val_acc: 0.1928\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4032 - acc: 0.2040 - val_loss: 2.7790 - val_acc: 0.1727\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 23s 126ms/step - loss: 2.3949 - acc: 0.2107 - val_loss: 2.7029 - val_acc: 0.1833\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.3989 - acc: 0.1895 - val_loss: 2.7237 - val_acc: 0.1801\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.4236 - acc: 0.2181 - val_loss: 2.7812 - val_acc: 0.1970\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 18s 101ms/step - loss: 2.3974 - acc: 0.2004 - val_loss: 2.6912 - val_acc: 0.1886\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 20s 106ms/step - loss: 2.3824 - acc: 0.2177 - val_loss: 2.6889 - val_acc: 0.1896\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3488 - acc: 0.2047 - val_loss: 2.8320 - val_acc: 0.1758\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 24s 129ms/step - loss: 2.3690 - acc: 0.2244 - val_loss: 2.6907 - val_acc: 0.1864\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.3732 - acc: 0.2198 - val_loss: 2.7386 - val_acc: 0.1790\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3761 - acc: 0.2061 - val_loss: 2.6945 - val_acc: 0.1822\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3882 - acc: 0.2209 - val_loss: 2.6541 - val_acc: 0.1780\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.4003 - acc: 0.2114 - val_loss: 2.7355 - val_acc: 0.1854\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.3820 - acc: 0.2096 - val_loss: 2.7905 - val_acc: 0.1758\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3860 - acc: 0.2022 - val_loss: 2.8086 - val_acc: 0.1780\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3725 - acc: 0.2135 - val_loss: 2.7012 - val_acc: 0.1854\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3204 - acc: 0.2121 - val_loss: 2.6909 - val_acc: 0.1875\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.3537 - acc: 0.2131 - val_loss: 2.6570 - val_acc: 0.1769\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3557 - acc: 0.2068 - val_loss: 2.7536 - val_acc: 0.1822\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3444 - acc: 0.2054 - val_loss: 2.6862 - val_acc: 0.1790\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3504 - acc: 0.2198 - val_loss: 2.6527 - val_acc: 0.1939\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.3605 - acc: 0.2050 - val_loss: 2.6505 - val_acc: 0.1843\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3664 - acc: 0.2152 - val_loss: 2.7011 - val_acc: 0.1822\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3466 - acc: 0.2198 - val_loss: 2.7268 - val_acc: 0.1875\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3268 - acc: 0.2124 - val_loss: 2.7334 - val_acc: 0.1822\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.3461 - acc: 0.2117 - val_loss: 2.7364 - val_acc: 0.1790\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3545 - acc: 0.2163 - val_loss: 2.7324 - val_acc: 0.1790\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3390 - acc: 0.2227 - val_loss: 2.7363 - val_acc: 0.1811\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.3052 - acc: 0.2350 - val_loss: 2.7609 - val_acc: 0.1833\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.3438 - acc: 0.2142 - val_loss: 2.6884 - val_acc: 0.1896\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.2956 - acc: 0.2255 - val_loss: 2.7798 - val_acc: 0.1833\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3151 - acc: 0.2368 - val_loss: 2.6938 - val_acc: 0.1875\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3295 - acc: 0.2089 - val_loss: 2.7555 - val_acc: 0.1833\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.3469 - acc: 0.2177 - val_loss: 2.6953 - val_acc: 0.1822\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3248 - acc: 0.2135 - val_loss: 2.7455 - val_acc: 0.1875\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3108 - acc: 0.2184 - val_loss: 2.7675 - val_acc: 0.1864\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3237 - acc: 0.2227 - val_loss: 2.7105 - val_acc: 0.1790\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.3243 - acc: 0.2339 - val_loss: 2.7115 - val_acc: 0.1769\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3111 - acc: 0.2149 - val_loss: 2.7079 - val_acc: 0.1875\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2991 - acc: 0.2308 - val_loss: 2.7399 - val_acc: 0.1811\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.3291 - acc: 0.2244 - val_loss: 2.6537 - val_acc: 0.1811\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2784 - acc: 0.2350 - val_loss: 2.6682 - val_acc: 0.1875\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2745 - acc: 0.2389 - val_loss: 2.6899 - val_acc: 0.1790\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 19s 103ms/step - loss: 2.3215 - acc: 0.2205 - val_loss: 2.7198 - val_acc: 0.1758\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3225 - acc: 0.2301 - val_loss: 2.6920 - val_acc: 0.1811\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3228 - acc: 0.2177 - val_loss: 2.6592 - val_acc: 0.1854\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.3109 - acc: 0.2181 - val_loss: 2.7658 - val_acc: 0.1790\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2779 - acc: 0.2332 - val_loss: 2.6813 - val_acc: 0.1864\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 19s 107ms/step - loss: 2.3191 - acc: 0.2064 - val_loss: 2.7335 - val_acc: 0.1907\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.3055 - acc: 0.2311 - val_loss: 2.7552 - val_acc: 0.1727\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2811 - acc: 0.2350 - val_loss: 2.7418 - val_acc: 0.1854\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.2905 - acc: 0.2272 - val_loss: 2.7764 - val_acc: 0.1684\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.3043 - acc: 0.2329 - val_loss: 2.7412 - val_acc: 0.1854\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2867 - acc: 0.2276 - val_loss: 2.6706 - val_acc: 0.1843\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.2995 - acc: 0.2297 - val_loss: 2.7168 - val_acc: 0.1917\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 23s 127ms/step - loss: 2.2842 - acc: 0.2230 - val_loss: 2.7352 - val_acc: 0.1833\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.3126 - acc: 0.2216 - val_loss: 2.7512 - val_acc: 0.1896\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 23s 126ms/step - loss: 2.2786 - acc: 0.2287 - val_loss: 2.6784 - val_acc: 0.1811\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 23s 126ms/step - loss: 2.2869 - acc: 0.2297 - val_loss: 2.6639 - val_acc: 0.1960\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.2817 - acc: 0.2209 - val_loss: 2.6841 - val_acc: 0.1949\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2952 - acc: 0.2251 - val_loss: 2.6784 - val_acc: 0.1939\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2923 - acc: 0.2248 - val_loss: 2.6851 - val_acc: 0.1854\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2756 - acc: 0.2371 - val_loss: 2.6986 - val_acc: 0.1960\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2505 - acc: 0.2389 - val_loss: 2.7183 - val_acc: 0.1907\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.2933 - acc: 0.2301 - val_loss: 2.7466 - val_acc: 0.1801\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2746 - acc: 0.2347 - val_loss: 2.7580 - val_acc: 0.1854\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2848 - acc: 0.2339 - val_loss: 2.7220 - val_acc: 0.1864\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2956 - acc: 0.2276 - val_loss: 2.7423 - val_acc: 0.1864\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2918 - acc: 0.2290 - val_loss: 2.6897 - val_acc: 0.1875\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.2991 - acc: 0.2308 - val_loss: 2.7353 - val_acc: 0.1917\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.3089 - acc: 0.2227 - val_loss: 2.7024 - val_acc: 0.1780\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2746 - acc: 0.2283 - val_loss: 2.7936 - val_acc: 0.1886\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2728 - acc: 0.2378 - val_loss: 2.7385 - val_acc: 0.2034\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2726 - acc: 0.2311 - val_loss: 2.6694 - val_acc: 0.1970\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 19s 105ms/step - loss: 2.2684 - acc: 0.2452 - val_loss: 2.7739 - val_acc: 0.1822\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2455 - acc: 0.2495 - val_loss: 2.7229 - val_acc: 0.1875\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 20s 110ms/step - loss: 2.2911 - acc: 0.2325 - val_loss: 2.7517 - val_acc: 0.1801\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2852 - acc: 0.2227 - val_loss: 2.7102 - val_acc: 0.1843\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2590 - acc: 0.2315 - val_loss: 2.6835 - val_acc: 0.1949\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2523 - acc: 0.2318 - val_loss: 2.7589 - val_acc: 0.1833\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2682 - acc: 0.2364 - val_loss: 2.7260 - val_acc: 0.1811\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2725 - acc: 0.2329 - val_loss: 2.7543 - val_acc: 0.1833\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.2839 - acc: 0.2227 - val_loss: 2.7280 - val_acc: 0.1801\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2914 - acc: 0.2396 - val_loss: 2.7517 - val_acc: 0.1939\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2633 - acc: 0.2336 - val_loss: 2.6917 - val_acc: 0.1949\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2543 - acc: 0.2339 - val_loss: 2.7424 - val_acc: 0.1939\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.3091 - acc: 0.2297 - val_loss: 2.7259 - val_acc: 0.1907\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2256 - acc: 0.2537 - val_loss: 2.7520 - val_acc: 0.1822\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2616 - acc: 0.2322 - val_loss: 2.7003 - val_acc: 0.1854\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2418 - acc: 0.2438 - val_loss: 2.6666 - val_acc: 0.1780\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 20s 108ms/step - loss: 2.2596 - acc: 0.2343 - val_loss: 2.7229 - val_acc: 0.1917\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2771 - acc: 0.2385 - val_loss: 2.7681 - val_acc: 0.1801\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2532 - acc: 0.2399 - val_loss: 2.6748 - val_acc: 0.1811\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2609 - acc: 0.2378 - val_loss: 2.7599 - val_acc: 0.1896\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 25s 135ms/step - loss: 2.2573 - acc: 0.2332 - val_loss: 2.7143 - val_acc: 0.1801\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2552 - acc: 0.2357 - val_loss: 2.7348 - val_acc: 0.1864\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2677 - acc: 0.2399 - val_loss: 2.7728 - val_acc: 0.1843\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2526 - acc: 0.2350 - val_loss: 2.7079 - val_acc: 0.1801\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2724 - acc: 0.2406 - val_loss: 2.6592 - val_acc: 0.1822\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2282 - acc: 0.2576 - val_loss: 2.7952 - val_acc: 0.1684\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.2609 - acc: 0.2410 - val_loss: 2.7596 - val_acc: 0.1939\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2414 - acc: 0.2336 - val_loss: 2.7779 - val_acc: 0.1854\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 23s 128ms/step - loss: 2.2471 - acc: 0.2381 - val_loss: 2.7752 - val_acc: 0.1801\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2695 - acc: 0.2322 - val_loss: 2.7508 - val_acc: 0.1886\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2724 - acc: 0.2272 - val_loss: 2.7321 - val_acc: 0.1928\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2838 - acc: 0.2406 - val_loss: 2.7657 - val_acc: 0.1907\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 19s 103ms/step - loss: 2.2699 - acc: 0.2339 - val_loss: 2.7792 - val_acc: 0.1780\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2368 - acc: 0.2435 - val_loss: 2.7990 - val_acc: 0.1663\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2247 - acc: 0.2534 - val_loss: 2.7535 - val_acc: 0.1758\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2527 - acc: 0.2361 - val_loss: 2.8247 - val_acc: 0.1896\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2560 - acc: 0.2389 - val_loss: 2.7121 - val_acc: 0.1737\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.2399 - acc: 0.2491 - val_loss: 2.8313 - val_acc: 0.1684\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2547 - acc: 0.2414 - val_loss: 2.7978 - val_acc: 0.1642\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.2533 - acc: 0.2364 - val_loss: 2.7982 - val_acc: 0.1758\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.2367 - acc: 0.2406 - val_loss: 2.8057 - val_acc: 0.1801\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2827 - acc: 0.2262 - val_loss: 2.8002 - val_acc: 0.1811\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.2201 - acc: 0.2463 - val_loss: 2.7347 - val_acc: 0.1833\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.2497 - acc: 0.2389 - val_loss: 2.7529 - val_acc: 0.1790\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2665 - acc: 0.2177 - val_loss: 2.7950 - val_acc: 0.1663\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 19s 104ms/step - loss: 2.2367 - acc: 0.2424 - val_loss: 2.7451 - val_acc: 0.1758\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2165 - acc: 0.2385 - val_loss: 2.7645 - val_acc: 0.1801\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 25s 137ms/step - loss: 2.2396 - acc: 0.2463 - val_loss: 2.8013 - val_acc: 0.1727\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2381 - acc: 0.2431 - val_loss: 2.7577 - val_acc: 0.1801\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2397 - acc: 0.2477 - val_loss: 2.7667 - val_acc: 0.1843\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2729 - acc: 0.2223 - val_loss: 2.8214 - val_acc: 0.1811\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.2592 - acc: 0.2368 - val_loss: 2.8696 - val_acc: 0.1790\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 20s 110ms/step - loss: 2.2164 - acc: 0.2512 - val_loss: 2.8494 - val_acc: 0.1769\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2280 - acc: 0.2495 - val_loss: 2.8313 - val_acc: 0.1695\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2496 - acc: 0.2449 - val_loss: 2.8329 - val_acc: 0.1706\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 25s 136ms/step - loss: 2.2472 - acc: 0.2396 - val_loss: 2.8420 - val_acc: 0.1769\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2726 - acc: 0.2276 - val_loss: 2.8255 - val_acc: 0.1748\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 20s 109ms/step - loss: 2.2620 - acc: 0.2484 - val_loss: 2.8086 - val_acc: 0.1727\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.2509 - acc: 0.2410 - val_loss: 2.8538 - val_acc: 0.1811\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2256 - acc: 0.2505 - val_loss: 2.8146 - val_acc: 0.1748\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2451 - acc: 0.2392 - val_loss: 2.8153 - val_acc: 0.1706\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 20s 110ms/step - loss: 2.2588 - acc: 0.2322 - val_loss: 2.8760 - val_acc: 0.1896\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.2617 - acc: 0.2431 - val_loss: 2.7535 - val_acc: 0.1801\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2421 - acc: 0.2498 - val_loss: 2.8778 - val_acc: 0.1790\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2249 - acc: 0.2579 - val_loss: 2.8505 - val_acc: 0.1843\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2386 - acc: 0.2392 - val_loss: 2.8867 - val_acc: 0.1674\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2525 - acc: 0.2406 - val_loss: 2.8594 - val_acc: 0.1981\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.2427 - acc: 0.2548 - val_loss: 2.7333 - val_acc: 0.1875\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2328 - acc: 0.2371 - val_loss: 2.9156 - val_acc: 0.1833\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2166 - acc: 0.2456 - val_loss: 2.8979 - val_acc: 0.1854\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 24s 132ms/step - loss: 2.2434 - acc: 0.2618 - val_loss: 2.8056 - val_acc: 0.1769\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2378 - acc: 0.2474 - val_loss: 2.8888 - val_acc: 0.1769\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2571 - acc: 0.2361 - val_loss: 2.9168 - val_acc: 0.1780\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2330 - acc: 0.2558 - val_loss: 2.8192 - val_acc: 0.1854\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2354 - acc: 0.2414 - val_loss: 2.8858 - val_acc: 0.1896\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 24s 135ms/step - loss: 2.2415 - acc: 0.2417 - val_loss: 2.8459 - val_acc: 0.1737\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2380 - acc: 0.2463 - val_loss: 2.9312 - val_acc: 0.1727\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 23s 129ms/step - loss: 2.2600 - acc: 0.2438 - val_loss: 2.8804 - val_acc: 0.1790\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 24s 130ms/step - loss: 2.2435 - acc: 0.2396 - val_loss: 2.9141 - val_acc: 0.1801\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2465 - acc: 0.2424 - val_loss: 2.9385 - val_acc: 0.1875\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 24s 134ms/step - loss: 2.2458 - acc: 0.2382 - val_loss: 2.8995 - val_acc: 0.1811\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 23s 130ms/step - loss: 2.2492 - acc: 0.2382 - val_loss: 2.9056 - val_acc: 0.1790\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2337 - acc: 0.2294 - val_loss: 2.8709 - val_acc: 0.1716\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 24s 131ms/step - loss: 2.2505 - acc: 0.2488 - val_loss: 2.8940 - val_acc: 0.1706\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2376 - acc: 0.2449 - val_loss: 2.8757 - val_acc: 0.1939\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 24s 133ms/step - loss: 2.2501 - acc: 0.2371 - val_loss: 2.8718 - val_acc: 0.1780\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=8e-5),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "24a408ab-714f-4cc3-bd98-30fdb536cb4e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'ro', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R19IJQSYoW7J"
      },
      "source": [
        "#Download the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/MyDrive/cut_panoramic/Model/Classification/All_Age/(8e-5)1_AC1_AllAge_Freeze_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1_รอบแรก_Gender_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}