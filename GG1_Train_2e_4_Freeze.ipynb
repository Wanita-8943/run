{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wanita-8943/run/blob/main/GG1_Train_2e_4_Freeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow7eWoNw6U-c"
      },
      "source": [
        "#เรียกใช้ CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1_2Fe8u81d5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e99def0-70f8-4829-8494-52fd90040b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "516b7153-8169-407a-e98c-fa3d14668c35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig_Age  Fig_Person_Sex  Age(year) Class  Class_Re       Filename  \\\n",
              "0           1               1          7  Y07F         0         V1.jpg   \n",
              "1           2               1          7  Y07F         0    Flip_V1.jpg   \n",
              "2           3               2          7  Y07F         0         V2.jpg   \n",
              "3           4               2          7  Y07F         0    Flip_V2.jpg   \n",
              "4           5               3          7  Y07F         0         V3.jpg   \n",
              "...       ...             ...        ...   ...       ...            ...   \n",
              "4745      121              77         25  Y25M         1  Flip_J463.jpg   \n",
              "4746      122              78         25  Y25M         1       J464.jpg   \n",
              "4747      123              78         25  Y25M         1  Flip_J464.jpg   \n",
              "4748      124              79         25  Y25M         1       J465.jpg   \n",
              "4749      125              79         25  Y25M         1  Flip_J465.jpg   \n",
              "\n",
              "                                          Path_filename     Sex Floder  \n",
              "0     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "1     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "2     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "3     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "4     /content/drive/My Drive/TVT_Gender/train/Femal...  Female   Both  \n",
              "...                                                 ...     ...    ...  \n",
              "4745  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4746  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4747  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "4748  /content/drive/My Drive/TVT_Gender/test/Male/J...    Male   Both  \n",
              "4749  /content/drive/My Drive/TVT_Gender/test/Male/F...    Male   Both  \n",
              "\n",
              "[4750 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d00fda54-b96b-43ca-881e-1e95fb301561\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig_Age</th>\n",
              "      <th>Fig_Person_Sex</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Class_Re</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>Flip_V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y07F</td>\n",
              "      <td>0</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/train/Femal...</td>\n",
              "      <td>Female</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4745</th>\n",
              "      <td>121</td>\n",
              "      <td>77</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J463.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J464.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>124</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/J...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>125</td>\n",
              "      <td>79</td>\n",
              "      <td>25</td>\n",
              "      <td>Y25M</td>\n",
              "      <td>1</td>\n",
              "      <td>Flip_J465.jpg</td>\n",
              "      <td>/content/drive/My Drive/TVT_Gender/test/Male/F...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4750 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d00fda54-b96b-43ca-881e-1e95fb301561')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d00fda54-b96b-43ca-881e-1e95fb301561 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d00fda54-b96b-43ca-881e-1e95fb301561');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/cut_panoramic/Data/New_Data_Gender.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxePnnn7TGW"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D-hCRloc3t39"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RooqSdBc7QHC"
      },
      "source": [
        "#กำหนดค่าพารามิเตอร์\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "thDb7U9B3xOo"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "width = 150\n",
        "height = 150\n",
        "epochs = 250\n",
        "NUM_TRAIN = 2850\n",
        "NUM_TEST = 950\n",
        "dropout_rate = 0.2\n",
        "input_shape = (height, width, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pumGmy6f3eSW"
      },
      "source": [
        "#Clone efficientnet repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "04e2d9d6-9b99-445e-ecbb-8e5945ccd730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Total 837 (delta 0), reused 0 (delta 0), pack-reused 837\u001b[K\n",
            "Receiving objects: 100% (837/837), 13.85 MiB | 24.42 MiB/s, done.\n",
            "Resolving deltas: 100% (497/497), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ],
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        " !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gqg_EUxrKkcK"
      },
      "outputs": [],
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uhCmH24AKmQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f800133-f3b1-49bf-a59a-3a1fdc71a643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16717576/16717576 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading pretrained conv base model\n",
        "# โหลดโมเดล มาโดยตัด output ของโมเดลออก เเต่ยังใช้ input อันเดิม\n",
        "# เเละโหลด weight ของโมเดล มาด้วยที่ชื่อว่า imagenet\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yWNKfQUt5rga"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(2, activation='softmax', name=\"fc_out\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NadBB12251jh",
        "outputId": "a2f54e46-1120-47f0-eafc-899e72b4153c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GepWq3yy53t5",
        "outputId": "e2ee26c7-5c4c-4ba9-c4eb-cf149f9d0d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ],
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ3dtKyJfYzs",
        "outputId": "7ab1da3d-6489-4a51-a636-0003262ebb5e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIWHby0gKpEq",
        "outputId": "bf8dc9c3-eb26-4b20-8e3d-0975350652ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnet-b0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 75, 75, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 75, 75, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " swish (Swish)                  (None, 75, 75, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 75, 75, 32)  288         ['swish[0][0]']                  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 75, 75, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_1 (Swish)                (None, 75, 75, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 1, 32)     0           ['swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 1, 1, 8)      264         ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " swish_2 (Swish)                (None, 1, 1, 8)      0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 1, 1, 32)     288         ['swish_2[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1, 1, 32)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 75, 75, 32)   0           ['activation[0][0]',             \n",
            "                                                                  'swish_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 75, 75, 16)   512         ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 75, 75, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 75, 75, 96)   1536        ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 75, 75, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_3 (Swish)                (None, 75, 75, 96)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 38, 38, 96)  864         ['swish_3[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 38, 38, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_4 (Swish)                (None, 38, 38, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1, 1, 96)     0           ['swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 1, 1, 4)      388         ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " swish_5 (Swish)                (None, 1, 1, 4)      0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 1, 1, 96)     480         ['swish_5[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 1, 1, 96)     0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 38, 38, 96)   0           ['activation_1[0][0]',           \n",
            "                                                                  'swish_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 24)   2304        ['multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 38, 38, 144)  3456        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_6 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 38, 38, 144)  1296       ['swish_6[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 38, 38, 144)  576        ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_7 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 1, 1, 144)    0           ['swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 6)      870         ['lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " swish_8 (Swish)                (None, 1, 1, 6)      0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_8[0][0]']                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 1, 1, 144)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 38, 38, 144)  0           ['activation_2[0][0]',           \n",
            "                                                                  'swish_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 38, 38, 24)   3456        ['multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 38, 38, 24)  96          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " drop_connect (DropConnect)     (None, 38, 38, 24)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 38, 38, 24)   0           ['drop_connect[0][0]',           \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 38, 38, 144)  3456        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 38, 38, 144)  576        ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " swish_9 (Swish)                (None, 38, 38, 144)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 19, 19, 144)  3600       ['swish_9[0][0]']                \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 19, 19, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_10 (Swish)               (None, 19, 19, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1, 1, 144)    0           ['swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 1, 1, 6)      870         ['lambda_3[0][0]']               \n",
            "                                                                                                  \n",
            " swish_11 (Swish)               (None, 1, 1, 6)      0           ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 1, 1, 144)    1008        ['swish_11[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 1, 1, 144)    0           ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)          (None, 19, 19, 144)  0           ['activation_3[0][0]',           \n",
            "                                                                  'swish_10[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 19, 19, 40)   5760        ['multiply_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 19, 19, 40)  160         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 19, 19, 240)  9600        ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 19, 19, 240)  960        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_12 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 19, 19, 240)  6000       ['swish_12[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 19, 19, 240)  960        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_13 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)              (None, 1, 1, 240)    0           ['swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_4[0][0]']               \n",
            "                                                                                                  \n",
            " swish_14 (Swish)               (None, 1, 1, 10)     0           ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 1, 1, 240)    0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)          (None, 19, 19, 240)  0           ['activation_4[0][0]',           \n",
            "                                                                  'swish_13[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 19, 19, 40)   9600        ['multiply_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 19, 19, 40)  160         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_1 (DropConnect)   (None, 19, 19, 40)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 40)   0           ['drop_connect_1[0][0]',         \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 19, 19, 240)  9600        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 19, 19, 240)  960        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_15 (Swish)               (None, 19, 19, 240)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 10, 10, 240)  2160       ['swish_15[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 10, 10, 240)  960        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_16 (Swish)               (None, 10, 10, 240)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_5 (Lambda)              (None, 1, 1, 240)    0           ['swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 1, 1, 10)     2410        ['lambda_5[0][0]']               \n",
            "                                                                                                  \n",
            " swish_17 (Swish)               (None, 1, 1, 10)     0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 1, 1, 240)    2640        ['swish_17[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 1, 1, 240)    0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)          (None, 10, 10, 240)  0           ['activation_5[0][0]',           \n",
            "                                                                  'swish_16[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 10, 10, 80)   19200       ['multiply_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 10, 10, 80)  320         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 10, 10, 480)  38400       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_18 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_18[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_19 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 1, 1, 480)    0           ['swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            " swish_20 (Swish)               (None, 1, 1, 20)     0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_20[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 1, 1, 480)    0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 10, 10, 480)  0           ['activation_6[0][0]',           \n",
            "                                                                  'swish_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 10, 10, 80)  320         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_2 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_2[0][0]',         \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 10, 10, 480)  38400       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_21 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 10, 10, 480)  4320       ['swish_21[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_22 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)              (None, 1, 1, 480)    0           ['swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_7[0][0]']               \n",
            "                                                                                                  \n",
            " swish_23 (Swish)               (None, 1, 1, 20)     0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_23[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 1, 1, 480)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_7 (Multiply)          (None, 10, 10, 480)  0           ['activation_7[0][0]',           \n",
            "                                                                  'swish_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 10, 10, 80)   38400       ['multiply_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 10, 10, 80)  320         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_3 (DropConnect)   (None, 10, 10, 80)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 10, 10, 80)   0           ['drop_connect_3[0][0]',         \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 10, 10, 480)  38400       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 10, 10, 480)  1920       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_24 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 10, 10, 480)  12000      ['swish_24[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 10, 10, 480)  1920       ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_25 (Swish)               (None, 10, 10, 480)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_8 (Lambda)              (None, 1, 1, 480)    0           ['swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 20)     9620        ['lambda_8[0][0]']               \n",
            "                                                                                                  \n",
            " swish_26 (Swish)               (None, 1, 1, 20)     0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 480)    10080       ['swish_26[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 1, 1, 480)    0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_8 (Multiply)          (None, 10, 10, 480)  0           ['activation_8[0][0]',           \n",
            "                                                                  'swish_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 10, 10, 112)  53760       ['multiply_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 10, 10, 112)  448        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 10, 10, 672)  75264       ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_27 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 10, 10, 672)  16800      ['swish_27[0][0]']               \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_28 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_9 (Lambda)              (None, 1, 1, 672)    0           ['swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_9[0][0]']               \n",
            "                                                                                                  \n",
            " swish_29 (Swish)               (None, 1, 1, 28)     0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_29[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 1, 1, 672)    0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_9 (Multiply)          (None, 10, 10, 672)  0           ['activation_9[0][0]',           \n",
            "                                                                  'swish_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 10, 10, 112)  448        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_4 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_4[0][0]',         \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 10, 10, 672)  75264       ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_30 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 10, 10, 672)  16800      ['swish_30[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 10, 10, 672)  2688       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_31 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_10 (Lambda)             (None, 1, 1, 672)    0           ['swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_10[0][0]']              \n",
            "                                                                                                  \n",
            " swish_32 (Swish)               (None, 1, 1, 28)     0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_32[0][0]']               \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 672)    0           ['conv2d_42[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_10 (Multiply)         (None, 10, 10, 672)  0           ['activation_10[0][0]',          \n",
            "                                                                  'swish_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 10, 10, 112)  75264       ['multiply_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 10, 10, 112)  448        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_5 (DropConnect)   (None, 10, 10, 112)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 112)  0           ['drop_connect_5[0][0]',         \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 10, 10, 672)  75264       ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 10, 10, 672)  2688       ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_33 (Swish)               (None, 10, 10, 672)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 5, 5, 672)   16800       ['swish_33[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 5, 5, 672)   2688        ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_34 (Swish)               (None, 5, 5, 672)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_11 (Lambda)             (None, 1, 1, 672)    0           ['swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 28)     18844       ['lambda_11[0][0]']              \n",
            "                                                                                                  \n",
            " swish_35 (Swish)               (None, 1, 1, 28)     0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 672)    19488       ['swish_35[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 1, 1, 672)    0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)         (None, 5, 5, 672)    0           ['activation_11[0][0]',          \n",
            "                                                                  'swish_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 5, 5, 192)    129024      ['multiply_11[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 5, 5, 192)   768         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 5, 5, 1152)   221184      ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_36 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_36[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_37 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_12 (Lambda)             (None, 1, 1, 1152)   0           ['swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_12[0][0]']              \n",
            "                                                                                                  \n",
            " swish_38 (Swish)               (None, 1, 1, 48)     0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_38[0][0]']               \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_12 (Multiply)         (None, 5, 5, 1152)   0           ['activation_12[0][0]',          \n",
            "                                                                  'swish_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 5, 5, 192)   768         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_6 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_6[0][0]',         \n",
            "                                                                  'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_39 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_39[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_40 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_13 (Lambda)             (None, 1, 1, 1152)   0           ['swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_13[0][0]']              \n",
            "                                                                                                  \n",
            " swish_41 (Swish)               (None, 1, 1, 48)     0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_41[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_13 (Multiply)         (None, 5, 5, 1152)   0           ['activation_13[0][0]',          \n",
            "                                                                  'swish_40[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_13[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 5, 5, 192)   768         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_7 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_7[0][0]',         \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_42 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 5, 5, 1152)  28800       ['swish_42[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_43 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_14 (Lambda)             (None, 1, 1, 1152)   0           ['swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_14[0][0]']              \n",
            "                                                                                                  \n",
            " swish_44 (Swish)               (None, 1, 1, 48)     0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_44[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_14 (Multiply)         (None, 5, 5, 1152)   0           ['activation_14[0][0]',          \n",
            "                                                                  'swish_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 5, 5, 192)    221184      ['multiply_14[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 5, 5, 192)   768         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " drop_connect_8 (DropConnect)   (None, 5, 5, 192)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 192)    0           ['drop_connect_8[0][0]',         \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 5, 5, 1152)   221184      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 5, 5, 1152)  4608        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_45 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 5, 5, 1152)  10368       ['swish_45[0][0]']               \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 5, 5, 1152)  4608        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_46 (Swish)               (None, 5, 5, 1152)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 1, 1, 1152)   0           ['swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 1, 1, 48)     55344       ['lambda_15[0][0]']              \n",
            "                                                                                                  \n",
            " swish_47 (Swish)               (None, 1, 1, 48)     0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 1, 1, 1152)   56448       ['swish_47[0][0]']               \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 1, 1, 1152)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " multiply_15 (Multiply)         (None, 5, 5, 1152)   0           ['activation_15[0][0]',          \n",
            "                                                                  'swish_46[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 5, 5, 320)    368640      ['multiply_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 5, 5, 320)   1280        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 5, 5, 1280)   409600      ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 5, 5, 1280)  5120        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " swish_48 (Swish)               (None, 5, 5, 1280)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,564\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,564\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_base.summary() #ดู Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J36J9EAE7qSB"
      },
      "source": [
        "#สร้างโฟลเดอร์ Train Valodation และ Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/TVT_Gender'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWEnlTSwazL5"
      },
      "source": [
        "\n",
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGPrsn9no_pa",
        "outputId": "12b7f0f5-902b-48a3-80dd-b391547e590c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2850 images belonging to 2 classes.\n",
            "Found 950 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Train ด้วย ImageDataGenerator ของ Keras ซึ่งจะเพิ่มข้อมูลเสริมระหว่างการฝึกเพื่อลดโอกาสเกิด overfitting\n",
        "#overfitting เกิดจากข้อมูลที่ซับซ้อนกันเกินไป\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, #โมเดลส่วนใหญ่ต้องใช้ RGB ในช่วง 0–1\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory #ไดเรกเป้าหมาย\n",
        "        train_dir,\n",
        "        # รูปภาพทั้งหมดจะถูกปรับขนาดตามความสูงและความกว้างของเป้าหมาย\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        #เนื่องจากเราใช้ categorical_crossentropy loss เราจึงต้องมีป้ายกำกับตามหมวดหมู่\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( #การดึงภาพจาก Directory มาเข้าโมเดล \n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6qUmmF856ZE",
        "outputId": "4eaabfcf-2057-4fbf-8324-6579e8818dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-7a569d3d450f>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "178/178 [==============================] - 164s 820ms/step - loss: 1.0990 - acc: 0.4972 - val_loss: 0.9084 - val_acc: 0.5350\n",
            "Epoch 2/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.9932 - acc: 0.5131 - val_loss: 0.7935 - val_acc: 0.5858\n",
            "Epoch 3/250\n",
            "178/178 [==============================] - 16s 87ms/step - loss: 0.9499 - acc: 0.5332 - val_loss: 0.8050 - val_acc: 0.6112\n",
            "Epoch 4/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.9009 - acc: 0.5565 - val_loss: 0.7076 - val_acc: 0.6345\n",
            "Epoch 5/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.8488 - acc: 0.5554 - val_loss: 0.6689 - val_acc: 0.6525\n",
            "Epoch 6/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.8509 - acc: 0.5462 - val_loss: 0.6529 - val_acc: 0.6451\n",
            "Epoch 7/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.7941 - acc: 0.5829 - val_loss: 0.6184 - val_acc: 0.6674\n",
            "Epoch 8/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.7888 - acc: 0.5783 - val_loss: 0.5944 - val_acc: 0.6822\n",
            "Epoch 9/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.7462 - acc: 0.5941 - val_loss: 0.6296 - val_acc: 0.6758\n",
            "Epoch 10/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.7222 - acc: 0.6101 - val_loss: 0.6316 - val_acc: 0.6610\n",
            "Epoch 11/250\n",
            "178/178 [==============================] - 16s 91ms/step - loss: 0.7367 - acc: 0.5992 - val_loss: 0.5742 - val_acc: 0.7066\n",
            "Epoch 12/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.7139 - acc: 0.6112 - val_loss: 0.6219 - val_acc: 0.6653\n",
            "Epoch 13/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6971 - acc: 0.6150 - val_loss: 0.5933 - val_acc: 0.6822\n",
            "Epoch 14/250\n",
            "178/178 [==============================] - 16s 91ms/step - loss: 0.6827 - acc: 0.6189 - val_loss: 0.5647 - val_acc: 0.7002\n",
            "Epoch 15/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6721 - acc: 0.6355 - val_loss: 0.5686 - val_acc: 0.7066\n",
            "Epoch 16/250\n",
            "178/178 [==============================] - 12s 63ms/step - loss: 0.6925 - acc: 0.6235 - val_loss: 0.5365 - val_acc: 0.7352\n",
            "Epoch 17/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6899 - acc: 0.6235 - val_loss: 0.6242 - val_acc: 0.6748\n",
            "Epoch 18/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6721 - acc: 0.6327 - val_loss: 0.5700 - val_acc: 0.6949\n",
            "Epoch 19/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6622 - acc: 0.6397 - val_loss: 0.5345 - val_acc: 0.7214\n",
            "Epoch 20/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6514 - acc: 0.6366 - val_loss: 0.5388 - val_acc: 0.7331\n",
            "Epoch 21/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6612 - acc: 0.6249 - val_loss: 0.5438 - val_acc: 0.7108\n",
            "Epoch 22/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6463 - acc: 0.6401 - val_loss: 0.5343 - val_acc: 0.7362\n",
            "Epoch 23/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6448 - acc: 0.6493 - val_loss: 0.5306 - val_acc: 0.7299\n",
            "Epoch 24/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6551 - acc: 0.6468 - val_loss: 0.5552 - val_acc: 0.7161\n",
            "Epoch 25/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6292 - acc: 0.6542 - val_loss: 0.5402 - val_acc: 0.7267\n",
            "Epoch 26/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6271 - acc: 0.6584 - val_loss: 0.5660 - val_acc: 0.6981\n",
            "Epoch 27/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6435 - acc: 0.6475 - val_loss: 0.5300 - val_acc: 0.7373\n",
            "Epoch 28/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6332 - acc: 0.6644 - val_loss: 0.5330 - val_acc: 0.7299\n",
            "Epoch 29/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6162 - acc: 0.6680 - val_loss: 0.5218 - val_acc: 0.7405\n",
            "Epoch 30/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6218 - acc: 0.6563 - val_loss: 0.5183 - val_acc: 0.7331\n",
            "Epoch 31/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6191 - acc: 0.6637 - val_loss: 0.5368 - val_acc: 0.7299\n",
            "Epoch 32/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6331 - acc: 0.6634 - val_loss: 0.5282 - val_acc: 0.7288\n",
            "Epoch 33/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6259 - acc: 0.6560 - val_loss: 0.5562 - val_acc: 0.7172\n",
            "Epoch 34/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6369 - acc: 0.6503 - val_loss: 0.5382 - val_acc: 0.7214\n",
            "Epoch 35/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6080 - acc: 0.6665 - val_loss: 0.5250 - val_acc: 0.7203\n",
            "Epoch 36/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6280 - acc: 0.6588 - val_loss: 0.5244 - val_acc: 0.7320\n",
            "Epoch 37/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6299 - acc: 0.6436 - val_loss: 0.7161 - val_acc: 0.6239\n",
            "Epoch 38/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6238 - acc: 0.6648 - val_loss: 0.5736 - val_acc: 0.7119\n",
            "Epoch 39/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6118 - acc: 0.6729 - val_loss: 0.5707 - val_acc: 0.7034\n",
            "Epoch 40/250\n",
            "178/178 [==============================] - 16s 91ms/step - loss: 0.6115 - acc: 0.6764 - val_loss: 0.5339 - val_acc: 0.7214\n",
            "Epoch 41/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6378 - acc: 0.6528 - val_loss: 0.6919 - val_acc: 0.6133\n",
            "Epoch 42/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6343 - acc: 0.6549 - val_loss: 0.5586 - val_acc: 0.7066\n",
            "Epoch 43/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6352 - acc: 0.6376 - val_loss: 0.5358 - val_acc: 0.7214\n",
            "Epoch 44/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6171 - acc: 0.6651 - val_loss: 0.5641 - val_acc: 0.6960\n",
            "Epoch 45/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6163 - acc: 0.6676 - val_loss: 0.5762 - val_acc: 0.6960\n",
            "Epoch 46/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6261 - acc: 0.6528 - val_loss: 0.6502 - val_acc: 0.6621\n",
            "Epoch 47/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6135 - acc: 0.6627 - val_loss: 0.5429 - val_acc: 0.7087\n",
            "Epoch 48/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6158 - acc: 0.6595 - val_loss: 0.6113 - val_acc: 0.6822\n",
            "Epoch 49/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6218 - acc: 0.6673 - val_loss: 0.6649 - val_acc: 0.6419\n",
            "Epoch 50/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6286 - acc: 0.6644 - val_loss: 0.5528 - val_acc: 0.7108\n",
            "Epoch 51/250\n",
            "178/178 [==============================] - 12s 63ms/step - loss: 0.6111 - acc: 0.6743 - val_loss: 0.5272 - val_acc: 0.7225\n",
            "Epoch 52/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6073 - acc: 0.6736 - val_loss: 0.5315 - val_acc: 0.7256\n",
            "Epoch 53/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6206 - acc: 0.6598 - val_loss: 0.5557 - val_acc: 0.7161\n",
            "Epoch 54/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6242 - acc: 0.6574 - val_loss: 0.5342 - val_acc: 0.7182\n",
            "Epoch 55/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6099 - acc: 0.6764 - val_loss: 0.6114 - val_acc: 0.6695\n",
            "Epoch 56/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6377 - acc: 0.6478 - val_loss: 0.6145 - val_acc: 0.6780\n",
            "Epoch 57/250\n",
            "178/178 [==============================] - 16s 91ms/step - loss: 0.6170 - acc: 0.6644 - val_loss: 0.5320 - val_acc: 0.7214\n",
            "Epoch 58/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6086 - acc: 0.6803 - val_loss: 0.5387 - val_acc: 0.7150\n",
            "Epoch 59/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6249 - acc: 0.6718 - val_loss: 0.5300 - val_acc: 0.7214\n",
            "Epoch 60/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6175 - acc: 0.6665 - val_loss: 0.5286 - val_acc: 0.7309\n",
            "Epoch 61/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6176 - acc: 0.6591 - val_loss: 0.7718 - val_acc: 0.5847\n",
            "Epoch 62/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6068 - acc: 0.6722 - val_loss: 0.5977 - val_acc: 0.6907\n",
            "Epoch 63/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6175 - acc: 0.6574 - val_loss: 0.5326 - val_acc: 0.7225\n",
            "Epoch 64/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6097 - acc: 0.6680 - val_loss: 0.5392 - val_acc: 0.7193\n",
            "Epoch 65/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6032 - acc: 0.6877 - val_loss: 0.5432 - val_acc: 0.7309\n",
            "Epoch 66/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6201 - acc: 0.6680 - val_loss: 0.5725 - val_acc: 0.6981\n",
            "Epoch 67/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6193 - acc: 0.6616 - val_loss: 0.5626 - val_acc: 0.7055\n",
            "Epoch 68/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6149 - acc: 0.6655 - val_loss: 0.5851 - val_acc: 0.7013\n",
            "Epoch 69/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6118 - acc: 0.6690 - val_loss: 0.5367 - val_acc: 0.7320\n",
            "Epoch 70/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6132 - acc: 0.6740 - val_loss: 0.5289 - val_acc: 0.7235\n",
            "Epoch 71/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6074 - acc: 0.6736 - val_loss: 0.5414 - val_acc: 0.7320\n",
            "Epoch 72/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6233 - acc: 0.6665 - val_loss: 0.6100 - val_acc: 0.6727\n",
            "Epoch 73/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6129 - acc: 0.6750 - val_loss: 0.5633 - val_acc: 0.7002\n",
            "Epoch 74/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6090 - acc: 0.6743 - val_loss: 0.5383 - val_acc: 0.7203\n",
            "Epoch 75/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6214 - acc: 0.6637 - val_loss: 0.5820 - val_acc: 0.6949\n",
            "Epoch 76/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6110 - acc: 0.6771 - val_loss: 0.5540 - val_acc: 0.7129\n",
            "Epoch 77/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6206 - acc: 0.6609 - val_loss: 0.5535 - val_acc: 0.7161\n",
            "Epoch 78/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6037 - acc: 0.6782 - val_loss: 0.6056 - val_acc: 0.6886\n",
            "Epoch 79/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6175 - acc: 0.6651 - val_loss: 0.5407 - val_acc: 0.7235\n",
            "Epoch 80/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6212 - acc: 0.6595 - val_loss: 0.5342 - val_acc: 0.7203\n",
            "Epoch 81/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6161 - acc: 0.6683 - val_loss: 0.5537 - val_acc: 0.7108\n",
            "Epoch 82/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6186 - acc: 0.6669 - val_loss: 0.5445 - val_acc: 0.7203\n",
            "Epoch 83/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6162 - acc: 0.6701 - val_loss: 0.5528 - val_acc: 0.7256\n",
            "Epoch 84/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6115 - acc: 0.6817 - val_loss: 0.5754 - val_acc: 0.7076\n",
            "Epoch 85/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6245 - acc: 0.6648 - val_loss: 0.5371 - val_acc: 0.7161\n",
            "Epoch 86/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6170 - acc: 0.6644 - val_loss: 0.5325 - val_acc: 0.7214\n",
            "Epoch 87/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6237 - acc: 0.6616 - val_loss: 0.5838 - val_acc: 0.7066\n",
            "Epoch 88/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.6133 - acc: 0.6782 - val_loss: 0.5507 - val_acc: 0.7214\n",
            "Epoch 89/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6201 - acc: 0.6620 - val_loss: 0.5637 - val_acc: 0.7097\n",
            "Epoch 90/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6022 - acc: 0.6838 - val_loss: 0.5747 - val_acc: 0.7034\n",
            "Epoch 91/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6102 - acc: 0.6754 - val_loss: 0.6024 - val_acc: 0.6822\n",
            "Epoch 92/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6179 - acc: 0.6609 - val_loss: 0.5470 - val_acc: 0.7267\n",
            "Epoch 93/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6322 - acc: 0.6524 - val_loss: 0.5581 - val_acc: 0.7044\n",
            "Epoch 94/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6121 - acc: 0.6821 - val_loss: 0.5507 - val_acc: 0.7097\n",
            "Epoch 95/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6161 - acc: 0.6630 - val_loss: 0.6115 - val_acc: 0.6706\n",
            "Epoch 96/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6249 - acc: 0.6701 - val_loss: 0.5439 - val_acc: 0.7076\n",
            "Epoch 97/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6056 - acc: 0.6725 - val_loss: 0.5343 - val_acc: 0.7225\n",
            "Epoch 98/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6146 - acc: 0.6556 - val_loss: 0.5496 - val_acc: 0.7161\n",
            "Epoch 99/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6113 - acc: 0.6694 - val_loss: 0.5291 - val_acc: 0.7447\n",
            "Epoch 100/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6183 - acc: 0.6704 - val_loss: 0.5949 - val_acc: 0.6854\n",
            "Epoch 101/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6209 - acc: 0.6616 - val_loss: 0.5857 - val_acc: 0.6875\n",
            "Epoch 102/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6197 - acc: 0.6584 - val_loss: 0.5526 - val_acc: 0.7076\n",
            "Epoch 103/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6169 - acc: 0.6750 - val_loss: 0.5484 - val_acc: 0.7214\n",
            "Epoch 104/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6118 - acc: 0.6683 - val_loss: 0.5788 - val_acc: 0.6981\n",
            "Epoch 105/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6163 - acc: 0.6736 - val_loss: 0.5432 - val_acc: 0.7172\n",
            "Epoch 106/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6069 - acc: 0.6785 - val_loss: 0.6178 - val_acc: 0.6716\n",
            "Epoch 107/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6185 - acc: 0.6630 - val_loss: 0.6647 - val_acc: 0.6377\n",
            "Epoch 108/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6247 - acc: 0.6570 - val_loss: 0.5720 - val_acc: 0.7023\n",
            "Epoch 109/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6155 - acc: 0.6673 - val_loss: 0.5973 - val_acc: 0.6864\n",
            "Epoch 110/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6208 - acc: 0.6620 - val_loss: 0.5393 - val_acc: 0.7161\n",
            "Epoch 111/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6235 - acc: 0.6570 - val_loss: 0.6038 - val_acc: 0.6886\n",
            "Epoch 112/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6070 - acc: 0.6673 - val_loss: 0.5572 - val_acc: 0.7203\n",
            "Epoch 113/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6133 - acc: 0.6680 - val_loss: 0.5578 - val_acc: 0.7140\n",
            "Epoch 114/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6185 - acc: 0.6725 - val_loss: 0.5621 - val_acc: 0.7097\n",
            "Epoch 115/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6303 - acc: 0.6750 - val_loss: 0.6475 - val_acc: 0.6472\n",
            "Epoch 116/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.5997 - acc: 0.6853 - val_loss: 0.5351 - val_acc: 0.7288\n",
            "Epoch 117/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6026 - acc: 0.6683 - val_loss: 0.5988 - val_acc: 0.6949\n",
            "Epoch 118/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6124 - acc: 0.6701 - val_loss: 0.5712 - val_acc: 0.7225\n",
            "Epoch 119/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6175 - acc: 0.6651 - val_loss: 0.6962 - val_acc: 0.6377\n",
            "Epoch 120/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6133 - acc: 0.6697 - val_loss: 0.5698 - val_acc: 0.7182\n",
            "Epoch 121/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6175 - acc: 0.6616 - val_loss: 0.6172 - val_acc: 0.6949\n",
            "Epoch 122/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6084 - acc: 0.6736 - val_loss: 0.6048 - val_acc: 0.6928\n",
            "Epoch 123/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6267 - acc: 0.6521 - val_loss: 0.6406 - val_acc: 0.6600\n",
            "Epoch 124/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6206 - acc: 0.6634 - val_loss: 0.5465 - val_acc: 0.7182\n",
            "Epoch 125/250\n",
            "178/178 [==============================] - 12s 63ms/step - loss: 0.6282 - acc: 0.6577 - val_loss: 0.5546 - val_acc: 0.7161\n",
            "Epoch 126/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6280 - acc: 0.6687 - val_loss: 0.5408 - val_acc: 0.7267\n",
            "Epoch 127/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6127 - acc: 0.6725 - val_loss: 0.6297 - val_acc: 0.6642\n",
            "Epoch 128/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.6168 - acc: 0.6711 - val_loss: 0.5516 - val_acc: 0.7246\n",
            "Epoch 129/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6166 - acc: 0.6673 - val_loss: 0.5402 - val_acc: 0.7256\n",
            "Epoch 130/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6342 - acc: 0.6613 - val_loss: 0.5440 - val_acc: 0.7225\n",
            "Epoch 131/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6065 - acc: 0.6803 - val_loss: 0.5420 - val_acc: 0.7172\n",
            "Epoch 132/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6127 - acc: 0.6673 - val_loss: 0.5446 - val_acc: 0.7182\n",
            "Epoch 133/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6078 - acc: 0.6828 - val_loss: 0.5587 - val_acc: 0.7087\n",
            "Epoch 134/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6138 - acc: 0.6733 - val_loss: 0.5615 - val_acc: 0.7108\n",
            "Epoch 135/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.6226 - acc: 0.6665 - val_loss: 0.6085 - val_acc: 0.6907\n",
            "Epoch 136/250\n",
            "178/178 [==============================] - 16s 91ms/step - loss: 0.5977 - acc: 0.6891 - val_loss: 0.5239 - val_acc: 0.7341\n",
            "Epoch 137/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6218 - acc: 0.6644 - val_loss: 0.5350 - val_acc: 0.7267\n",
            "Epoch 138/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6118 - acc: 0.6750 - val_loss: 0.5775 - val_acc: 0.7087\n",
            "Epoch 139/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6214 - acc: 0.6644 - val_loss: 0.5285 - val_acc: 0.7299\n",
            "Epoch 140/250\n",
            "178/178 [==============================] - 12s 63ms/step - loss: 0.6167 - acc: 0.6697 - val_loss: 0.5406 - val_acc: 0.7193\n",
            "Epoch 141/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6170 - acc: 0.6637 - val_loss: 0.5442 - val_acc: 0.7246\n",
            "Epoch 142/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6145 - acc: 0.6750 - val_loss: 0.5394 - val_acc: 0.7256\n",
            "Epoch 143/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6213 - acc: 0.6669 - val_loss: 0.5411 - val_acc: 0.7246\n",
            "Epoch 144/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6172 - acc: 0.6697 - val_loss: 0.5677 - val_acc: 0.7097\n",
            "Epoch 145/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6200 - acc: 0.6725 - val_loss: 0.6247 - val_acc: 0.6758\n",
            "Epoch 146/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6196 - acc: 0.6701 - val_loss: 0.5352 - val_acc: 0.7278\n",
            "Epoch 147/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6271 - acc: 0.6637 - val_loss: 0.5414 - val_acc: 0.7267\n",
            "Epoch 148/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6120 - acc: 0.6796 - val_loss: 0.6174 - val_acc: 0.6833\n",
            "Epoch 149/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.5991 - acc: 0.6793 - val_loss: 0.5619 - val_acc: 0.7076\n",
            "Epoch 150/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6036 - acc: 0.6803 - val_loss: 0.5521 - val_acc: 0.7182\n",
            "Epoch 151/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6146 - acc: 0.6662 - val_loss: 0.5375 - val_acc: 0.7278\n",
            "Epoch 152/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6038 - acc: 0.6793 - val_loss: 0.5503 - val_acc: 0.7076\n",
            "Epoch 153/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6061 - acc: 0.6701 - val_loss: 0.5984 - val_acc: 0.7023\n",
            "Epoch 154/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6213 - acc: 0.6630 - val_loss: 0.5638 - val_acc: 0.7087\n",
            "Epoch 155/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6339 - acc: 0.6514 - val_loss: 0.5373 - val_acc: 0.7299\n",
            "Epoch 156/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6178 - acc: 0.6683 - val_loss: 0.5892 - val_acc: 0.7002\n",
            "Epoch 157/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6252 - acc: 0.6560 - val_loss: 0.5990 - val_acc: 0.6970\n",
            "Epoch 158/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6180 - acc: 0.6754 - val_loss: 0.5765 - val_acc: 0.7076\n",
            "Epoch 159/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.5966 - acc: 0.6909 - val_loss: 0.5896 - val_acc: 0.7013\n",
            "Epoch 160/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6136 - acc: 0.6736 - val_loss: 0.5631 - val_acc: 0.7150\n",
            "Epoch 161/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6188 - acc: 0.6683 - val_loss: 0.5477 - val_acc: 0.7172\n",
            "Epoch 162/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6115 - acc: 0.6789 - val_loss: 0.5672 - val_acc: 0.7140\n",
            "Epoch 163/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6228 - acc: 0.6634 - val_loss: 0.6866 - val_acc: 0.6356\n",
            "Epoch 164/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6076 - acc: 0.6814 - val_loss: 0.5383 - val_acc: 0.7288\n",
            "Epoch 165/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6274 - acc: 0.6549 - val_loss: 0.6688 - val_acc: 0.6451\n",
            "Epoch 166/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6140 - acc: 0.6715 - val_loss: 0.5283 - val_acc: 0.7373\n",
            "Epoch 167/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6175 - acc: 0.6743 - val_loss: 0.5501 - val_acc: 0.7119\n",
            "Epoch 168/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6177 - acc: 0.6641 - val_loss: 0.5297 - val_acc: 0.7362\n",
            "Epoch 169/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6131 - acc: 0.6630 - val_loss: 0.5551 - val_acc: 0.7097\n",
            "Epoch 170/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6162 - acc: 0.6725 - val_loss: 0.5643 - val_acc: 0.7076\n",
            "Epoch 171/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6106 - acc: 0.6736 - val_loss: 0.5405 - val_acc: 0.7288\n",
            "Epoch 172/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6230 - acc: 0.6725 - val_loss: 0.5393 - val_acc: 0.7246\n",
            "Epoch 173/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6129 - acc: 0.6687 - val_loss: 0.7972 - val_acc: 0.5784\n",
            "Epoch 174/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6217 - acc: 0.6673 - val_loss: 0.5341 - val_acc: 0.7150\n",
            "Epoch 175/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6032 - acc: 0.6807 - val_loss: 0.6227 - val_acc: 0.6864\n",
            "Epoch 176/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6177 - acc: 0.6740 - val_loss: 0.5736 - val_acc: 0.7129\n",
            "Epoch 177/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6194 - acc: 0.6697 - val_loss: 0.5367 - val_acc: 0.7235\n",
            "Epoch 178/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6118 - acc: 0.6623 - val_loss: 0.6463 - val_acc: 0.6547\n",
            "Epoch 179/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6179 - acc: 0.6673 - val_loss: 0.5488 - val_acc: 0.7352\n",
            "Epoch 180/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6281 - acc: 0.6560 - val_loss: 0.5571 - val_acc: 0.7055\n",
            "Epoch 181/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6102 - acc: 0.6789 - val_loss: 0.5375 - val_acc: 0.7341\n",
            "Epoch 182/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6190 - acc: 0.6570 - val_loss: 0.5480 - val_acc: 0.7150\n",
            "Epoch 183/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6136 - acc: 0.6768 - val_loss: 0.5428 - val_acc: 0.7267\n",
            "Epoch 184/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6015 - acc: 0.6842 - val_loss: 0.5604 - val_acc: 0.7097\n",
            "Epoch 185/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6092 - acc: 0.6701 - val_loss: 0.5496 - val_acc: 0.7256\n",
            "Epoch 186/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6181 - acc: 0.6655 - val_loss: 0.5436 - val_acc: 0.7256\n",
            "Epoch 187/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6195 - acc: 0.6669 - val_loss: 0.5204 - val_acc: 0.7362\n",
            "Epoch 188/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6028 - acc: 0.6785 - val_loss: 0.5277 - val_acc: 0.7352\n",
            "Epoch 189/250\n",
            "178/178 [==============================] - 12s 64ms/step - loss: 0.6161 - acc: 0.6722 - val_loss: 0.5433 - val_acc: 0.7182\n",
            "Epoch 190/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.6085 - acc: 0.6694 - val_loss: 0.5644 - val_acc: 0.7140\n",
            "Epoch 191/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6201 - acc: 0.6708 - val_loss: 0.5532 - val_acc: 0.7172\n",
            "Epoch 192/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6213 - acc: 0.6637 - val_loss: 0.5674 - val_acc: 0.7055\n",
            "Epoch 193/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6228 - acc: 0.6637 - val_loss: 0.5948 - val_acc: 0.6896\n",
            "Epoch 194/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6352 - acc: 0.6662 - val_loss: 0.5577 - val_acc: 0.7119\n",
            "Epoch 195/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6071 - acc: 0.6757 - val_loss: 0.5422 - val_acc: 0.7235\n",
            "Epoch 196/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6085 - acc: 0.6775 - val_loss: 0.5395 - val_acc: 0.7182\n",
            "Epoch 197/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6195 - acc: 0.6591 - val_loss: 0.5694 - val_acc: 0.7076\n",
            "Epoch 198/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6210 - acc: 0.6602 - val_loss: 0.5698 - val_acc: 0.7013\n",
            "Epoch 199/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6095 - acc: 0.6807 - val_loss: 0.6250 - val_acc: 0.6716\n",
            "Epoch 200/250\n",
            "178/178 [==============================] - 16s 88ms/step - loss: 0.6095 - acc: 0.6761 - val_loss: 0.5718 - val_acc: 0.7055\n",
            "Epoch 201/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.6241 - acc: 0.6598 - val_loss: 0.5512 - val_acc: 0.7066\n",
            "Epoch 202/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6246 - acc: 0.6665 - val_loss: 0.5428 - val_acc: 0.7193\n",
            "Epoch 203/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6289 - acc: 0.6598 - val_loss: 0.5577 - val_acc: 0.7129\n",
            "Epoch 204/250\n",
            "178/178 [==============================] - 17s 94ms/step - loss: 0.6085 - acc: 0.6708 - val_loss: 0.6084 - val_acc: 0.6886\n",
            "Epoch 205/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6117 - acc: 0.6708 - val_loss: 0.5363 - val_acc: 0.7182\n",
            "Epoch 206/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6025 - acc: 0.6800 - val_loss: 0.5316 - val_acc: 0.7288\n",
            "Epoch 207/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6016 - acc: 0.6882 - val_loss: 0.5367 - val_acc: 0.7267\n",
            "Epoch 208/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6148 - acc: 0.6775 - val_loss: 0.5683 - val_acc: 0.7087\n",
            "Epoch 209/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6150 - acc: 0.6771 - val_loss: 0.5436 - val_acc: 0.7193\n",
            "Epoch 210/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6076 - acc: 0.6680 - val_loss: 0.5450 - val_acc: 0.7246\n",
            "Epoch 211/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6128 - acc: 0.6740 - val_loss: 0.6051 - val_acc: 0.6917\n",
            "Epoch 212/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6105 - acc: 0.6860 - val_loss: 0.5602 - val_acc: 0.7108\n",
            "Epoch 213/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6267 - acc: 0.6648 - val_loss: 0.5394 - val_acc: 0.7235\n",
            "Epoch 214/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6181 - acc: 0.6694 - val_loss: 0.6003 - val_acc: 0.6907\n",
            "Epoch 215/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6180 - acc: 0.6708 - val_loss: 0.5520 - val_acc: 0.7193\n",
            "Epoch 216/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6284 - acc: 0.6694 - val_loss: 0.5610 - val_acc: 0.7129\n",
            "Epoch 217/250\n",
            "178/178 [==============================] - 17s 95ms/step - loss: 0.6192 - acc: 0.6789 - val_loss: 0.5331 - val_acc: 0.7278\n",
            "Epoch 218/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6328 - acc: 0.6637 - val_loss: 0.5486 - val_acc: 0.7150\n",
            "Epoch 219/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6266 - acc: 0.6577 - val_loss: 0.5372 - val_acc: 0.7246\n",
            "Epoch 220/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6317 - acc: 0.6606 - val_loss: 0.5428 - val_acc: 0.7182\n",
            "Epoch 221/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6145 - acc: 0.6630 - val_loss: 0.5366 - val_acc: 0.7225\n",
            "Epoch 222/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6076 - acc: 0.6743 - val_loss: 0.5396 - val_acc: 0.7278\n",
            "Epoch 223/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.5908 - acc: 0.6838 - val_loss: 0.5448 - val_acc: 0.7161\n",
            "Epoch 224/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6116 - acc: 0.6669 - val_loss: 0.5373 - val_acc: 0.7309\n",
            "Epoch 225/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6174 - acc: 0.6648 - val_loss: 0.5358 - val_acc: 0.7278\n",
            "Epoch 226/250\n",
            "178/178 [==============================] - 16s 89ms/step - loss: 0.6306 - acc: 0.6641 - val_loss: 0.5424 - val_acc: 0.7214\n",
            "Epoch 227/250\n",
            "178/178 [==============================] - 16s 90ms/step - loss: 0.6236 - acc: 0.6581 - val_loss: 0.6154 - val_acc: 0.6758\n",
            "Epoch 228/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.6314 - acc: 0.6613 - val_loss: 0.5950 - val_acc: 0.6949\n",
            "Epoch 229/250\n",
            "178/178 [==============================] - 17s 90ms/step - loss: 0.6137 - acc: 0.6725 - val_loss: 0.5440 - val_acc: 0.7214\n",
            "Epoch 230/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6255 - acc: 0.6567 - val_loss: 0.5400 - val_acc: 0.7203\n",
            "Epoch 231/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6147 - acc: 0.6768 - val_loss: 0.5425 - val_acc: 0.7182\n",
            "Epoch 232/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6136 - acc: 0.6658 - val_loss: 0.5532 - val_acc: 0.7108\n",
            "Epoch 233/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6215 - acc: 0.6606 - val_loss: 0.5399 - val_acc: 0.7256\n",
            "Epoch 234/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6193 - acc: 0.6701 - val_loss: 0.5788 - val_acc: 0.7044\n",
            "Epoch 235/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6077 - acc: 0.6655 - val_loss: 0.5436 - val_acc: 0.7119\n",
            "Epoch 236/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6160 - acc: 0.6722 - val_loss: 0.5408 - val_acc: 0.7161\n",
            "Epoch 237/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6129 - acc: 0.6793 - val_loss: 0.5468 - val_acc: 0.7108\n",
            "Epoch 238/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6061 - acc: 0.6771 - val_loss: 0.5849 - val_acc: 0.6992\n",
            "Epoch 239/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6172 - acc: 0.6757 - val_loss: 0.6073 - val_acc: 0.6811\n",
            "Epoch 240/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6083 - acc: 0.6662 - val_loss: 0.6295 - val_acc: 0.6600\n",
            "Epoch 241/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6305 - acc: 0.6588 - val_loss: 0.5761 - val_acc: 0.6917\n",
            "Epoch 242/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6244 - acc: 0.6665 - val_loss: 0.5399 - val_acc: 0.7150\n",
            "Epoch 243/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6180 - acc: 0.6733 - val_loss: 0.5616 - val_acc: 0.7119\n",
            "Epoch 244/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6128 - acc: 0.6708 - val_loss: 0.5501 - val_acc: 0.7182\n",
            "Epoch 245/250\n",
            "178/178 [==============================] - 17s 94ms/step - loss: 0.6223 - acc: 0.6690 - val_loss: 0.5514 - val_acc: 0.7235\n",
            "Epoch 246/250\n",
            "178/178 [==============================] - 17s 91ms/step - loss: 0.6110 - acc: 0.6697 - val_loss: 0.6464 - val_acc: 0.6684\n",
            "Epoch 247/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.6049 - acc: 0.6694 - val_loss: 0.5429 - val_acc: 0.7108\n",
            "Epoch 248/250\n",
            "178/178 [==============================] - 17s 94ms/step - loss: 0.6297 - acc: 0.6524 - val_loss: 0.6939 - val_acc: 0.6419\n",
            "Epoch 249/250\n",
            "178/178 [==============================] - 17s 92ms/step - loss: 0.6006 - acc: 0.6849 - val_loss: 0.6061 - val_acc: 0.7013\n",
            "Epoch 250/250\n",
            "178/178 [==============================] - 17s 93ms/step - loss: 0.5987 - acc: 0.6828 - val_loss: 0.6584 - val_acc: 0.6621\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-4),\n",
        "              metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Y3K89-CM-dfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "6e008424-3ad7-4004-e471-2bee71195873"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABw2ElEQVR4nO2deXhU1f3/X2cmmSyQhSSArAnI4lIEEcENxK2itW6tK1rUtrjUr9harVZbV9rqrwt1L1YtRVq1FreKpYprq1agsiiKICQQtoSEbGRPzu+PO+fm3Dv3zkw2ApPzep48mbnbnLuc932fz9mElBKDwWAwJC6Bnk6AwWAwGLoXI/QGg8GQ4BihNxgMhgTHCL3BYDAkOEboDQaDIcExQm8wGAwJjhH6XogQ4nUhxKyu3rYnEUIUCiFO7YbjSiHEqPDnx4UQP4tn2w78zkwhxL86mk6DIRrCtKM/MBBC1Ghf04EGoCX8/Wop5aJ9n6r9ByFEIfA9KeWbXXxcCYyWUm7sqm2FEAXAZiBZStncJQk1GKKQ1NMJMMSHlLKv+hxN1IQQSUY8DPsL5nncPzChmwMcIcR0IUSxEOInQoidwNNCiH5CiH8IIUqFEHvCn4dq+7wjhPhe+PMVQoh/CyF+Hd52sxDijA5uO0II8Z4QoloI8aYQ4hEhxDM+6Y4njfcKIf4TPt6/hBB52vrLhRBFQogyIcTtUa7PFCHETiFEUFt2nhBiTfjzZCHEh0KICiHEDiHEw0KIkM+x/iSEuE/7fnN4n+1CiKtc235DCPGJEKJKCLFVCHGXtvq98P8KIUSNEOJYdW21/Y8TQiwXQlSG/x8X77Vp53XOEUI8HT6HPUKIl7R15wghVoXP4SshxIzwckeYTAhxl7rPQoiCcAjru0KILcBb4eV/C9+HyvAzcri2f5oQ4jfh+1kZfsbShBCvCSH+z3U+a4QQ53mdq8EfI/SJwUFADpAPzMa6r0+Hvw8H6oCHo+w/BVgP5AEPAE8KIUQHtv0L8DGQC9wFXB7lN+NJ46XAlcAAIAT8GEAIcRjwWPj4g8O/NxQPpJT/BfYCJ7uO+5fw5xbgh+HzORY4BbguSroJp2FGOD2nAaMBd/3AXuA7QDbwDeBaIcS54XXTwv+zpZR9pZQfuo6dA7wGPBg+t98Crwkhcl3nEHFtPIh1nRdihQIPDx/rd+E0TAb+DNwcPodpQKHPb3hxInAocHr4++tY12kA8D9ADzX+GjgKOA7rOb4FaAUWAJepjYQQ44EhWNfG0B6klObvAPvDynCnhj9PBxqB1CjbTwD2aN/fwQr9AFwBbNTWpQMSOKg922KJSDOQrq1/BngmznPySuMd2vfrgH+GP/8ceFZb1yd8DU71OfZ9wFPhzxlYIpzvs+2NwIvadwmMCn/+E3Bf+PNTwK+07cbo23ocdx7wu/DngvC2Sdr6K4B/hz9fDnzs2v9D4IpY16Y91xkYhCWo/Ty2+4NKb7TnL/z9LnWftXMbGSUN2eFtsrBeRHXAeI/tUoE9WPUeYL0QHu2OPJXof8bRJwalUsp69UUIkS6E+EO4KFyFFSrI1sMXLnaqD1LK2vDHvu3cdjBQri0D2OqX4DjTuFP7XKulabB+bCnlXqDM77ew3Pv5QogU4Hzgf1LKonA6xoTDGTvD6fgFlruPhSMNQJHr/KYIId4Oh0wqgWviPK46dpFrWRGWm1X4XRsHMa7zMKx7tsdj12HAV3Gm1wv72gghgkKIX4XDP1W0lQzywn+pXr8VfqafAy4TQgSAS7BKIIZ2YoQ+MXA3nboJGAtMkVJm0hYq8AvHdAU7gBwhRLq2bFiU7TuTxh36scO/meu3sZRyHZZQnoEzbANWCOgLLNeYCfy0I2nAKtHo/AV4BRgmpcwCHteOG6up23asUIvOcGBbHOlyE+06b8W6Z9ke+20FDvY55l6s0pziII9t9HO8FDgHK7yVheX6VRp2A/VRfmsBMBMrpFYrXWEuQ3wYoU9MMrCKwxXheO+d3f2DYYe8ArhLCBESQhwLfLOb0vgCcJYQ4oRwxek9xH6W/wLMwRK6v7nSUQXUCCEOAa6NMw3PA1cIIQ4Lv2jc6c/Acsv14Xj3pdq6UqyQyUifYy8BxgghLhVCJAkhLgIOA/4RZ9rc6fC8zlLKHVix80fDlbbJQgj1IngSuFIIcYoQIiCEGBK+PgCrgIvD208Cvh1HGhqwSl3pWKUmlYZWrDDYb4UQg8Pu/9hw6YuwsLcCv8G4+Q5jhD4xmQekYbmlj4B/7qPfnYlVoVmGFRd/DiuDezGPDqZRSvkZ8AMs8d6BFcctjrHbX7EqCN+SUu7Wlv8YS4SrgSfCaY4nDa+Hz+EtYGP4v851wD1CiGqsOoXntX1rgbnAf4TV2ucY17HLgLOw3HgZVuXkWa50x8s8ol/ny4EmrFJNCVYdBVLKj7Eqe38HVALv0lbK+BmWA98D3I2zhOTFn7FKVNuAdeF06PwYWAssB8qB+3Fq05+BcVh1PoYOYDpMGboNIcRzwBdSym4vURgSFyHEd4DZUsoTejotByrG0Ru6DCHE0UKIg8NF/RlYcdmXejhZhgOYcFjsOmB+T6flQMYIvaErOQir6V8NVhvwa6WUn/RoigwHLEKI07HqM3YROzxkiIIJ3RgMBkOCYxy9wWAwJDj73aBmeXl5sqCgoKeTYTAYDAcUK1eu3C2l7O+1br8T+oKCAlasWNHTyTAYDIYDCiGEuze1jQndGAwGQ4ITl9ALIWYIIdYLITYKIW71WP+78HCmq4QQXwohKrR1Ldq6V7ow7QaDwWCIg5ihm/DgR49gDcdaDCwXQrwSHj8EACnlD7Xt/w84UjtEnZRyQpel2GAwGAztIh5HPxlraNpNUspG4FmsjjB+XILV3dxgMBgM+wHxCP0QnMOxFuMcLtVGCJEPjMA57keqEGKFEOIjbeIF936zw9usKC0tjS/lBoPBYIiLrq6MvRh4QUrZoi3Ll1JOwho4ap4QImI4UinlfCnlJCnlpP79PVsHGQwGg6GDxCP023COuz0U/3GxL8YVtpFSbgv/34TVPf7IyN0MBoPB0F3EI/TLgdHCmvg5hCXmEa1nwmNV98Oa8kwt66fGlRbW5MXHYw1TajC0i8bGRp5++mlaW1t7OikGwwFHTKGXUjYD1wNLgc+B56WUnwkh7hFCnK1tejHWPJ764DmHAiuEEKuBt7Hm2DRCb2g3S5cu5aqrruJ///tfTyfFYDjgiKtnrJRyCdasN/qyn7u+3+Wx3wdYEwYYDJ2ioqICgLq6up5NiMFwAGJ6xnYDTU1NtLS0xN7QEDdVVVUANDT4TVhlMBj8MELfDZx44on86Ec/6ulkJBRK6BsbG3s4JQbDgcd+N6jZgU5zczPLly9nz549PZ2UhKK6uhowjt5g6AjG0XcRNTU1PPDAA3z11Vc0Nzezfv1624UaOo8J3XQNpaWlPPTQQ5gJh3oXRujbyRdffMF1111HU1OTY/mjjz7KT37yE374Q2vYHyklK1eu7IkkJiQmdNM1vPjii9xwww0UFRVx99138/7773fL7zzzzDP87Gc/o7a2tluOb2gfRug9mDt3Lvfdd5/nuiVLlvDYY4+xfPlyx/KMjAwAXn/9dXuZGVe/6zChm65BGZSKigruvfdennvuuXbt/89//pNvfetbMUsEv/nNb7jvvvuYPn26KT3sBxih9+CVV15xCDZAZWUl9fX1VFZWAkQ4oaSktuqOjIwMCgoKIl4Gho5zIDr6uro6hBA89NBDPZ0UGyX027Zto6WlxX6e4+X9999n8eLFVFVVMWLECF5++eWIbaSUbNiwgUAgwPLly+2XtKHnMELvQVVVVYRzPPnkk7n55pvt9tzvvfeeY71eRB09ejRTpkzh3Xffpb6+PuL4ra2t/Oc//+n6hHcha9asoaKigqqqKlavXt3TyTkgY/TqWbnhhht6NiEazc3NABQWFgK0ux5JvSg2b95MYWGhZwe2nTt3snfvXo4++mj7u6FnMULvQXV1tcM5Njc3s2bNGjZt2mQ7oH//+9+OtvK60I8aNYrvf//7lJSU8Kc//Sni+A888AAnnHAC7777bvedhAf/+Mc/KCqKnG3s7bff5rPPPnMsmzZtGvfeey8nnHACEyZM2Ecp9OdADN3sj527lNCr56C9jl4vEYBVuetmw4YNAJxwwgkA7Nq1q2OJ3cds3bq13aGsAwUj9B64HX1xcTHNzc2Ul5fbLq2qqoo1a9bY27gd/cknn8yUKVP45S9/yfbt2x3H/9e//gXsW9Gqr6/nm9/8JjNmzIhY953vfMdRJ9HY2EhlZSUrV65k7dq1AD3eAexADd0o9u7dy9atW/nZz37WZddy4cKFvPXWW7E31OgqoVfPdDShnzp1KnDgCP2jjz7KxRdfnJAhVyP0LlpbWyMc/ebNmwEoLy+nsrKSAQMGADhccG1tLaFQiPPOO49zzjkHIQT3338/paWljBs3zj4GwJYtWwDo27fvvjglAL788kuAiHhpfX09xcXFjiJ8TU0NgCNk09MC2x2hm3feeYerr766y47nRhf6Tz75hBdffJH77ruPL774okuO/7Of/YyHH344rm3vu+8+Fi1aZAu1Ct0ood+2bRtnnXVWTFF2O/rdu3dHbLNhwwaSk5Pt0E1XC/2bb77JhRde2OUlpuLiYsBqjJFoGKF3oUROF7ZNmzYBsGfPHiorK/na174GtDn9lpYWamtryc7OZvHixfYDfuKJJ/LOO+9QXl7OsmXL7ONt3WrN46Lc1b7g888/B2Ds2LGO5SrDq/OGtpeBKr1A95c+1HX0oqWlhb1793Z5OpYuXcr8+fPbdR/a8/u6EC1fvpyysjKgzfF68d3vfpfTTjvNFlLFLbfcwpw5cxzLysrK4q7o/POf/8yLL77o6+hffvllXnvttZg9utX+ShRLS0tpaWlxNDfesGEDI0eOZODAgQQCgS4X+hdeeIG//e1v/PjHP457n8bGRiZNmsQ///lPx3IpJdOnT+fJJ5+0r/nLL79sG6NEwQi9C69YsO7o9+zZw+DBg+nXrx9bt25l5syZzJw5k9raWtLT0yOON3HiRJKSkuyXBbS9RLpK6EtKSmJmJiX0Bx/snPdFpctL6HU64ui3bdvmeFlE47TTTuMnP/mJ5zo9bV1ZslDXX71EYvHyyy+Tmppqh7P27Nljv7S9cDv68vJyoE3ot2/fHrH/U089xZtvvsn555/vWL548WKHWWhsbKSmpiZuoW9ubrb/oM1lV1VVIaUkGAwCVvPhaM0hvRz9HXfcwXHHHQfAxx9/zJo1axg9ejTBYJC8vLwuF3p1/R599FHWrYtvMNytW7eycuVK3n77bcfyNWvW8O677/LGG2+wfft2jjrqKADeeOONqMerq6tzlNL3d4zQu/CKBSsxbGlpYfv27WRlZTF06FCKi4v58MMP2bBhg6/QJyUlMXz4cPuh0MdT74pYbWtrKyeffDKXXHJJ1O2U0IdCIcdylS5dTPXPivY6aSklU6dO5aabbopr+6+++so30+phpa509Eq0vM7XiyeffBKwwmBLly5lzJgxHHnkkb5iq4Q+JSWFHTt2OBz9woULGTNmDGPHjuWpp56y9xk8eDDQVtJSx9m0aZO9P2C/NOJtNdPc3ExTU1OEuWhubqaurs4+XkVFBatWrfI9jjtGv3v3bj766CPWrl3Ll19+yZQpU9i4cSNHHHEEAAMHDuwWoVclU5U3t2zZwkcffeS7j0pvUVERRUVF9rZLliyxj7N9+3aOP/54hg4dGtGqzs1DDz3E+PHje7zuKl6M0LvwigW73Xh2djbDhg1jw4YNbN26laqqKl+hBxg5cqR9DL1itisc/Ysvvshnn33GJ598EtWJKaF3P5hd5ejffPNNXnvtNfv72rVr7SZ48aCLjRs9PV3p6JVoxevoVbijX79+3HTTTYRCIcrKynj88cc9t1dCn5+fT0lJiX1+y5cv56qrrmLChAkcddRRXH311fZ5qea4emngyy+/RErJ7t277XusjhWvo29qarL/3FRWVjpeIl4i98wzz/D5559HOPqWlhZWrVpFQ0ODXafzxBNP8POfW6OYxxL6P/3pT3YJKR7q6urYunUrxx9/PGCVZsG6xscee6wjvbpxUOktKiri9ttvZ8aMGbS0tNhCv27dOqqrqxkyZAjTpk3j/fffj5qfvvzyS6qrqzs0ptVLL73Ehx9+GHvDLsQIvQuVcRobG+0bvXnzZvLy8uxtlKNX4hmP0CvnrL80ukLof/WrXwGWE/PLUC0tLXbMUQn9zp07ueKKK+zeu15Cf84559ihnlhO+rTTTuOss86yH3yVgVRGjEV9fb1nplmwYAG/+c1v7O/d4eirq6uZM2eOfT/9UJXojY2NVFdXc9ppp3Hqqafym9/8xjNdbqFXYrpq1Sqam5u5//77+c53vkNzc7Pd1lwdRxd6la7m5mb73qhjdTR0o1NZWUl5eTlZWVn2tjqNjY1cfvnlTJs2zb5m+otBhedUSeCkk04iJSUFsITerx19U1MT3/ve97jzzjvjOgewSn6AHSoqKSmJ6KvS3NzMlVde6XgB647+008/pbKyknfeeYcPPviArKws+2U/ePBgpk6dyo4dO+zf8kK9OPzMiR9NTU2cd955dvr3FUboXehF4aamJvbu3UtJSYkduwNL6IcNa5tGt7q6OqrQjxgxgtLSUubMmcM111xjL9fd9bJlyzj00EPth/a+++7jnnvuiZrWvXv3smLFCqZNmwYQIVRPPPEEF1xwAZs2bbIFRIWOlixZwoIFC2z3VlNTY7/YlHj89re/5de//jUQW2BVz2DVCsQt9CUlJRx33HGsX7+e++67LyJz+zn6hx56yBHa0NPx8ccfc/LJJ3dY/JVoffXVVzz44IMRFXVulKA1NjbS2NhISkoKc+bMYdeuXZ4uWBf60tJSRwuVfv36MWXKFIYMGQK0CZG6/7oo6/dVHUN39PEMMeAXuoE2R9+/f38gstSnTEpjY6NniUChHP1BBx1kLzvooIPYtWuXZxq3bt1KS0sLb7zxRtwlNRWfHz9+PH369KG0tNRx7aWUbN++nebmZod5UcK8Y8cOu9XTj370I1pbWx0tr5Sjh7be76tWreK4445z9JZX90t/4cVDT3WUNELvQhf6xsZGO2Mdeuih9vLs7GyGDh1qf6+rq6OysjKqowd48MEHHZlWz3Tf+973+OKLL+wH8m9/+xuvvvpq1LSqsMg3v/lNIFLoZ8+ezQsvvOAQMJWJVeWborW11RYZJfQZGRm2M1MZ8ayzzrKL5TrK+T/44INUVVXxwQcfkJKSwu7du2ltbeXFF1/kww8/5N///jcvvPACf/1r2xzyaqKWPXv2RAiCHuoKhUIOQXjjjTd4++23o1aIKl544QWEEA53qa6/+o1oIqava2xspKGhgVAoxMknn0xqaqr9YtNRQj98+HBaWlrYsmULAwcOBOD0008nKSnJjslv27bNbnmknLXaX7+vSljU/9bW1riaGXoJvXoGlKNXQu+el1eJa35+ftRrtGrVKjIyMujTp4+9bODAgdTV1XnWg+hhw3//+9+ex2xtbXWUVFVaRo8eTf/+/SkpKXFc+/r6ejvEVlNTQ1NTE7t373Y8R8oYrFmzhkMOOYQLLrjAXjd48GBGjBgBtFVYv/vuu3z44YeceeaZLFq0COi4o1dpnTJlSrv26yxG6F3oReGGhga7+VlBQYG93O3owXooYgk9wF/+8hceffRRwOmcVMZVlaXbt2+P2WJFZZSpU6eSkZHB2rVreeedd2yxVO30f/Ob35CdnW0Ljvs8Dz/8cKAtfKP+9+3b1xZ6lTk+/vhjPvnkk4i0qH12797N0qVLaWlp4YQTTqC1tZXy8nL7Ad++fTvbt2+nqKjITosSqpaWFke6mpubHZk8Ly/P4d6VwMcTJ1UvlqVLl9rL3BWLzc3NlJSUsH79ese+hYWFjlYYuqNPT0/npJNOYsmSJaxcudJxz3RHD5ZonXjiiQCcfbY13bLu6NW5ZWdnO/b//PPP7dCh29FDfBWyqoSgC7X67aqqKsrKyuz+IW5Hr8S1oKDAsX9OTo5ju23btjFo0CDHMvVi8wor6q1WvF6UYBme4cOH2805N2zYQP/+/cnKymLAgAGUlJTw5ptv2tvX1NTYIbaamhoeffRRRo8ezcaNG0lOTra3Gz16NACXXXaZI38OHjzYfuaV8VHX95hjjuGaa67hs88+i3jhxos6Tz0t+wIj9C7cjt5L6N2OHqxifbTQDcCYMWO4+OKLOfXUUwGno1cC19LSQkNDA7t3747Za1FllJEjR3LIIYfw+OOPc9JJJ9mVW+PHjwesuOQJJ5xAcnKy7daUMK9YsYL/+7//A9oqJaurqwkGg6SmptovnoaGBlpbWykrK/NM1969e+3fW7x4MYAtalu3brUz4+bNmyktLaWxsdEWWN2R6gK2a9cuh7vMy8tzOHqV+SsqKnyHd1AccsghAI6xWdxC39TUxF133WWXkBRf//rX+cY3vmF/b2hosB09wJlnnsmXX37JpEmTuPfee+3t6urqCAaDtqCCNSzA6tWrufjiiwHIzc0lOTnZIfT9+vWz929paWHDhg125aOXwHjF6YuKiuz7oM7N7ejVC8jt6P2EPiMjw7G/EsikpCQCAUtK9LANWKUZgE8//ZR//etfjk54mzZtIjk5mWnTpvkOB7J27VoaGxt555137PNSvztgwAB27tzJhg0b7JdUTU2Nw9EXFRVRUVHBihUrOPLII+3j3nTTTaSlpXHZZZfRr18/srKyyMjIICMjg0AgQEpKiv1cVlZWkpaWxvPPP4+U0tF+vz2Ofvv27XYny309lIcRehfupnxK1AYNGmS/6VVlLLQNTwz4Cn1OTg7HHHMMP/rRjxBC2EVmr3hpc3MzO3bsACwBixZ/3bRpE3379iUvL88RWlJpFkLYy6ZNm0YgELAzcU1NDYFAgIkTJ5Kbm2svA0s4MjIyEEI4QjeVlZW0trbarrWmpoabbrqJ0tJSxyBW//jHPwiFQnbx9IUXXqC2thYhhGOMflUi0SvT9IyjBFiVTPwcfXl5Od/61rd45JFHIq7Rn//8Z9566y1b1D/44AN7nZfQV1ZW2tdf4S4x1NfX09zcbF+bc889l5EjR5KVleUYFqOuro60tDRbQMES9iOOOMK+N4FAgEGDBrFt2zb7OuiOfuvWrTQ0NNgtSpTA69fJLfS1tbWcccYZfOtb32LFihVIKe1OTfozp8yLitGrUoOf0Ltj9AcddBDp6ekUFBTY+7od/fHHH0///v158MEHOffcc7njjjvsdZs2bSI/P59x48bZLYvcKNFWcfjKykr7+gwYMIB169bR2Nhoi7gu9Hv37nXk5ylTpiCEYODAgcyePZtdu3aRn5+PEIIRI0Y4XshpaWkOR69K8cccc4yjP4O6H3/84x8drc68UOcwbNgwI/Q9jZ+jz8rKsp1WdnY2ffr04bvf/S7f/e537e39hF4IwYcffmhX+qiKS682uM3NzXb8r6mpyXP0S8WmTZsYMWIEQgguuugiu5js1URv2rRpBINBR+hGibkSUrfQAw5Hr8IG6prceOON/Pa3v+Wvf/0rTU1N5Ofnk5eXR01NDaNHj7bjzy+99BJCCKZOneoYNkKVSPR06qKqrsNtt93GrFmz6NOnT8QYRGCFVlQHIjd33nknDz/8sC2Gn3zyif1ZiZYSdhXaULFdhRJEVRJTv6OuzdChQ/nqq68455xzHE36lNArtwmR4Q6wQijbt2+375vu6JXIHn300QQCAfseRHP0P//5z/niiy/o06cPv/jFL+x77hZ6FX5UPbxzc3MJBAK0trby17/+1R5100/oMzIyyMvLs3vBQqTQJycnc/HFF/P222/b/QEUmzdvZsSIEYwePZqqqirPcXNUGEaJpP5s9u/f3z4fL6Gvqalx5OcRI0YwaNAgDj30UIQQDpN21VVXccUVV9jfU1NTHY4+MzMTsO6Dfg3U+FfXX389t912W0T6wRo08NJLL+Xtt9+mb9++TJkyxQh9T+OO0asHJSsry86kqrLsj3/8IxdeeKG9vZ/Qu4nm6FWnLEW08M3mzZvtYuyZZ57JP/7xD8Ap9BMnTuTmm29m0qRJBINBR+hGCbxb6PV1eoxeiUtlZSW1tbV2ByL1e3369LFLFocddpgtcOvWrWPUqFGMGTPG8XJTmd4vdKOuw1VXXcWf/vQnR2VsbW2tva1qOur1Uqyurqa6uto+t5aWFrviz6syVp+YQ9HQ0MC5555rh0LUM6KujeLQQw9l+/bt9j1TQq83zVWlJ53Bgwezbds2z9CNEtmxY8eSk5PjcPSpqamO9CjeeecdTj31VG666SZefPFF+xjuGH1OTg4ZGRn2CzcnJ8c2A5deeikPPfQQ9fX1jmal+v6ZmZncdddd/OhHP7KF3h26ASsODpbh2bRpk+3cN23axMiRI+14udfQEEVFRQghWL9+PSUlJQ6h11+gaoRVt9Dr12bw4MHce++93HLLLRG/83//93+OntlpaWkOoVd5XpVa1fUqKyvjhRdeoKGhgbVr13o2DLjvvvv461//ylNPPcXxxx9Penq6Efqexs/RZ2Zm0q9fP0KhkJ3B1HJFvEKvHL1y77qLbW5udgi9X4WslNJ29AqVLl3oDz/8cB544AGCwWBE6EaJuWol4eXo9dCNcpNVVVW88MIL9u8qR6wL/aGHHkpubq4dojjiiCNshw+WG4xH6IPBoB36SElJsTOIcvPQJhBerU+qq6uprKykpqaGMWPGkJWVxbPPPgu0OXp1z3Wh1+9JQ0MDKSkptoNX4uHuZazOXTXfU0KflJRkC3w8jl4P3WzYsIH09HQGDx5Mbm6uw9Grkoa7Mnbr1q0UFBTYcX0l1G5Hn52dTVZWli30ytHrL+PCwkJbmN0drjIzM7nyyis5/fTTfR09WOL4xBNPcNttt1FfX8/OnTvtCmDl6CFS6JubmykuLrbrej766COqqqoihD49PZ0xY8YAkZWxVVVVdsVnQUEBV111FWeccUZEGt2kpqba98NL6FNSUhg9ejTl5eUsXLjQvr/uCYugrY6uubmZadOmOZ7jfYURehdeMfqkpCTS0tLIyckhKyvLEfvujNC3tLQwdOhQR+ZvaWlxDGjl5+hLSkqora11tBjwEvq0tDR7vVfoBiIdvV/oRrlJKaWjN6Of0AeDQTsDjB8/3o6BhkIhjjrqqLhCNwcddJBdAkpJSbEdvS70ytG7hb6hoYHGxkaqqqqoqakhLy+PCy64gMWLF7N3796IpoK649XT0djYSCgUsq+Fuk5ejh6sovq//vUvamtr7euvXlZ+jl4JH0Q6+lGjRiGEIC8vz1EZqypT3aXQkpIShg0bZgucui5K6IcOHUogEGDEiBEOoVeOXq8A15ujeoVuFNEcvRCC733ve/b49Js2bbLFuKCggIKCAoLBYITQb9++nZaWFkcv2JqaGjvPKaEfNWqUnZaioiJqa2vJyMiwhf7MM89k2bJlTJ48OSJtfvg5+qFDhzJw4ED7xbt+/Xree+89brjhBvLz8z1bD+lm7bTTTiMlJYX6+npqa2s9XwzdgRF6F9XV1bbDVY5eifuRRx4ZMQlHPJWxbmJVxsbj6NU2euuf9gh9tNBNLEcPlrhmZ2eTmZnpqDSdNm2aHYeEtsyoO/rBgwdz8MEHe1bGrlu3jt/+9rd2xxe9giwUCtlOSBWRU1JS7KZ77tCNEsCqqiqqq6vp27cvl112GTU1Nbz88ssRQh8tdJOSkoIQguTkZF9HP3LkSEKhELfddhunn346NTU19vUfMGAAgUDAYQwU6roowXU7euV4dUdfXl5uO3pd6JVJGDp0aITQqyaWBx98MFu3buWkk04iKyvLNje5ubmOZwTaXqiZmZmeoRtFNEevUM528+bN9gsrLy+P5ORkRowYESH0KgSjWnNt376d1tZWR4werKaS6hlWpalDDjmE1tZWSkpKyM7O5uSTT3YYtFj4Cb0Qgm984xtMnjyZ3Nxc+4U1bdo0Tj31VM/+AHv27OG4446jqKiIo48+2nb0L7zwAmeeeWZE5X93YITeRVVVlR1TVY5e3eS7777bnjRE0RGh10M3blQ4R7k63dHPmzfP7kSlnK0eRool9KqiDWLH6KM5esBu0paZmelw9BMnTqS6utrO1H5Cf8ghh7Bz50527drlcOILFy7kpptuori4mO3btzvCPV6hm8MOO8xe73b0SgBV6KZv375MnTqVtLQ0Vq5cGbejV0KvrodfjD4pKckWZbCESRf6nJwcuxmijrpG6uWl7n1NTQ2bNm2yj6kcfV1dHXV1dQwbNgwhhEPo1XXRHb2aFEc5etVRSwhhDz4G2OnzEvq8vDzP0I1i+vTpnHDCCRGjo+qoF9OmTZvsEJ0qzY4ePTpC6JWIHn744QQCAfv6uEM3utDrTY7BKgXoeTRe9NCNanWjePLJJ3n22WfttAshOOqooxgzZgxlZWURobQ9e/bQr18/u6lpamoqDQ0NtpmId6ylzmCE3oUu9KrYr99kN8Fg0C4BdCR040ZVxqowgO4s582bZ09NqIRe73ihC31LSwuNjY1xhW5UunVH71UZqzv6r776iv79+zscvd4jUjFgwAB7snTlzocMGWIX499//31boPWXVn19fYTQ65WxxcXF5OXlORykn6Ovra2loqLCbiOdlpZGY2NjxItWj2G7QzfqOqSkpPg6eoA5c+bYDrS4uNi+/rNmzfIdyVNda/UiVY7+iy++oLm5OcLRqyacSuCqq6spLy/nmGOOsXtBezl6JdT6RPa//OUv7c9eoRsl9P3797evmTpvXegnT57M+++/HzUPpKamMmTIEDZt2mRfX/VSU0Kv/7Zy9Pn5+WRlZdnCr57bQYMGce2113LxxRfbv6t6i+t1V16lqFgoR9/S0uIIF+moMNwhhxxCRkaG/XJxD19cUVFhnydYz5A6LkTvkd1V9GqhP+uss7j77rvt7y0tLVRWVtpFQrej98MtmLGIpx29Enrd0dfX19vfleDpYqMLvRK9eEI3wWCQ9PR0qqqq2LFjh+MloMSisbHR4egbGxttR68co5fQ33TTTTzxxBMIIejfvz8pKSkMGzaMiRMnkp6e7hB6XdT37t3rmUGUo9+1axcDBw50rPdz9GDFmtX5qhBQtNCN29Gr6xwKhXxj9ADf//73eeCBBwAcMfqzzjqLW2+9NWJ7iBR6dU5K6NR1mTBhAg0NDfzud78D2npEV1VV8fHHH/Pf//7X7ksQLXSjm4Ps7GxWr17Ngw8+SCgUsp8R9SwpF606qzU1NdlOtiNOecSIEWzevDnC0U+cOJG9e/fazVM3b97M888/z8CBA+nTpw/Z2dkRjj4QCPDoo48yfvx4AoEAffr0sYVe7+DYEaFXjl5vdedGpV1V0KqXi96EFKxnSb28oe250cdO6m56tdCvWrXKUam4du1aGhoamDRpEtAWo4/1oKj17RX6lpaWCHFU44MPGDCAYDDoEPq6urqI8fJ1oU9KSiIpKcmu6AHiCt2AJTZPP/00Q4YMoaGhwZGZkpOTbUevi/GAAQMcGcBL6CdPnsxFF11kH+uf//wnP/7xjwmFQhx77LG89957nkK/Z88eWltbHcdMSUmhtbWVlpYWu4OPnoHcQq8XoVtaWhxC7zVAl1foprW1laamJs/QjZejBxzNKfXr74c6R7ejVyUl9f30009HCMFzzz3HqFGjGDRoEBkZGVRXV9thj6qqKrKzs+nbt6+n0LsdPVhhNdU7WoVuVJq2bt1KMBikX79+9otQiah+v+JFCf2ePXsIBoP2c6YGElPt5WfOnMnmzZvt4UK8hN5N3759aWxsJBAIOIYo6cgLSTl6vR+NG+XoldB7OfrW1lYqKysjDAu0PWNG6LuZ+vp6hzioh+y0004D4nf07RX6QCCAEMJz+jzddWVlZTlCN7qjV4LkFhvlRLzCIcqttba2OuLwYGUSvSeuvk456bKyMkcrH+Xo9WPEYvr06Xa4Zdq0aaxevdqO8auQB7SN6aILvbvzVm5uriMD+YVuFHoFs5fQe1XGqu/xxOgVesuaeJ4Jt6NXlf/quiihz83NtSu51cTbSug3btxoH0+JnFvowbpGbqHXUaEbdd2Li4vJzMx0XLPp06ezdu1ae0rN9jBkyBB27txJWVkZ/fr1sytIVWhP5cHi4mLOP/98e6at7OxsuyTlZ7zUdVSt4xSdCd1EE/qxY8eSlJTE9OnTAeyhFHRHX1lZiZTSU+jdz1h3EpfQCyFmCCHWCyE2CiEiyp9CiN8JIVaF/74UQlRo62YJITaE/2Z1Ydo7TV1dne18wYoXDx8+nFGjRgHxxeih/aEbsNy3EvVAIGC7JPV2T0pKIisry37QVMzdHbpxD47kFnqv0I06Z7ej19G/KwdcVlbmqGxTMXqFl6OPxqRJk5BS2uPPzJs3z261oHpJ6tfU3XkrLy/PM3RTWVnJzTffHDFxdSxH7xW6UaEi9ZKJFaOHzjv61NRUUlNTIxw9WB3joM0BZ2ZmOhw9tLXEclfGgnWNog2opZ4RlabS0lIyMzNJTk62r1lycnKHRB6s5pdNTU1s3LjR0axYCOGY8KOmpsbxPOnXwM+hq+379+/v2Le7QjdHHnkkFRUVjmuhTzIERNRFwH4auhFCBIFHgDOAw4BLhBCH6dtIKX8opZwgpZwAPAQsDu+bA9wJTAEmA3cKIfqxHyCltFsvqO/vvfee3aEBsG90Vzt6cAr9HXfcYfe6VK40KSmJ7Oxs+2FQghMtRg/RhV6FbvTRKRVuodfDHsrR7969m0GDBtmlBLejb8/5Q1vzuG3btpGSkuLoWBTL0ZeVlUU4enXO7733Hr/+9a8dI1Xq56hi9F7T6vkJve7olXD6CX16erq9fTxCr66bOufU1FTS0tLs39FF7vLLL3cMsqZi9Bs2bOCkk04Cojv6urq6qI7eHboBS+RCoZB9nM6MvKhKc+vWrYvoPDZ16lS2b9/Opk2b2Lt3r+OZjEfo9TGR9H27K3QDkeZGhaYUKv/GCt3ceOONviN4dgXxOPrJwEYp5SYpZSPwLHBOlO0vAdRg46cDb0gpy6WUe4A3gBmdSXBX0dTUhJTSzkxfffUVJSUlTJ061c7Ae/bscYwP7kdHhD4YDNoiomLr4BR63dGr5fX19Q432h6hV25NH29eoTLG888/z4033sjll19urwuFQuzevdseD0VdD13o09LSPJsORkOJut46RV3DaI6+tLSU5uZmR4w+GAxSX1+PlNJ+CaqOVAq9yWh7Hb0u9O70uFGdmyA+oVeV4epZTElJsfdLSUlxhN8KCgpYunSp/ZLMzMxk165dbN68mWOPPZYHHnjAHn+pI0KvnhE93UroVfq6Quh37NjhED/AMQ9sY2OjQ0T1bWMJff/+/R1C31FH39jYaD8H8R5DzSan6sLU/l6VsbrQz58/P+agaJ0hnpw5BNAHcCgOL4tACJEPjADeas++QojZQogVQogVXgMbdQfq4Vf/VdOtsWPHOgQFYt9kXeziRVWagpVxVAWtvkwXej2zVlVVdSp0E83Rn3jiifzud79zhB9SUlLsmaL69evnGD1QiX488Xk3ytFVVVVFCL36PXdlLLRVUuqOfsiQIXbFqbo27qng9CajSuj1TjRejl4dy0vo/Ry9ShvE/0yo8wwGg3ZPbHAKhBczZsxg165dtLS0MHr0aG6++Wa7B2hHhb61tdUxkmRWVpZjiOvOCL3ec9bt6JWAq964fo7eL0To5+g7GqOHtucwltlTjBgxgoaGBvsc4gndqGc2nglkOkpXV8ZeDLwgpWzX1OhSyvlSyklSykn6kK7diRJU5VJU78oBAwbYD3K8Nzk/P5+BAwdGzUBudKHXHb3u8vXQjV7RWFlZ2aHQjcrEXkI/bNgwDj30UMdAUQpd6DMzMz0dfXvj82BdV/WCU67VHcbwCt2oSsrc3Fzy8/MJBAKMGzcOaCvxgJWB9PP3al6p31u9Hb07ZKbH6PXr4kd7hd7dbyFeob/wwgvtehO9sxZ4C72UMqpQq9CN3kggMzPT8Zx1haOHSKFXz5K6v15Cr/pCeKE7er0k2NHQDbS9dOIVenV+Sk+8hF496+oZU+319bqUriYeod8G6NMpDQ0v8+Ji2sI27d13n+J29ErIBg4ciBCCUChkO/pYN3nOnDl8+umn7fp9FWoAK+MooVfpUaGbXbt28ZOf/MTRzLKysrJDoRuVib1CN7/85S99p3NToRtoE3ohBDk5OZ0SeiGEnQFUOlUmiBa6Ud388/LyGDFiBFu3brUHqqqrq3NUbg0aNMh27e7QTXNzs/37gUDAEbpRY+9HC91Ec/TtCd1A2/VT5x+v0CclJXHvvfeSk5NjzxSm8KqMVfv4oUp9utCr0I37uB2hb9++tiC7Qzfq/ug9rRW60Ec7NljXXrWrh46HbsAS7OTkZEf4LBrKKKnnN5qjd08C1NNCvxwYLYQYIYQIYYn5K+6NhBCHAP2AD7XFS4GvCyH6hSthvx5e1uMoIdQdvXLRQLuEPhQKOUId8eB29O7QTVJSkj1uzAMPPMCHH7ZdVt3Rd1XoRg3a5kVKSortPrKyssjOziYvL49gMNgpoYdI56t6rkZz9HroBqz23Gr/uro6x8iAWVlZdhp111xXV4eU0r7fOTk5dugmJSUFKaU9E5baR0+Dviye84pFRx09wCWXXEJpaWnEtm7z4F7uhSr16T1UVegmnv3jQblev9BNLEfvh+7o1fdgMNiukKpC7bNr166IgQyjoX5bGceKigpH73mIfG72C6GXUjYD12MJ9OfA81LKz4QQ9wghztY2vRh4VmrBPSllOXAv1stiOXBPeFmPowRVTZFXUlJiDzwFzsGy4sls7cXP0euhm29961t2axy9qWBnQjd+Qh8N/TcyMzO5/PLL7enU1Euwo0KvMruezvT0dPt8vRy9EnqvZox66AYsYXALfSgUsscXOfnkk/nOd77D5MmTbUd/yimnEAgEuPnmmyMcvZ5J9wdHrwgEAixau4iCeQUE7g5QMK+Av3z6F5KSktol9F6hm6509NAWp3cLvboGKlzSGUevvqvJddqLug/6uFPxoBy9Eno1zo2ehp4Q+rhezVLKJcAS17Kfu77f5bPvU8BTHUxft+GuoNq1a5cjPh0KhWxn0V63Hg+xHL3KTOrh1YW+qqrKDjG4M208zSu9QjfR0B/MzMxMvvnNb9rzqrpFtL14Od/09HS7TblfZWwgEHCUtFTGdIdudKHXQzdK6AcNGsSvf/1rZs6cab/0p0yZwuTJk7nrrrvsDmL6EAhe1yWe84pGZxw9wKK1i5j96mxqmyyxKKosYvarswkkBSKEPp529G6hj3f/eFCO3i2ggUCAjIyMLnX0He2MpK7/1q1b29VnQJV+9NCN+zzdz40+JlN30Wt7xuqVm3V1dbajV+g3wy+k0RncrW68HD20CZ2Xow+FQhFupTscvVvodTobulHXVo+B6i5e/6yHbtQkGYpojl4JlTqWPl6Nus66801KSuLSSy8FYP369UBk6Eaf+9cLZQ5m/WOW7bAXrV3ku726Fx119Lcvu90WeUVtUy1NNHUodOOujNXFvauE3itfZWRkRHX0mZmZESUXdV3V3AVq8Lw+ffp0KD4PbddfH+QwHoQQDBgwwBG6cd/D/TJ0k6joD39tbS0lJSX2mNrQlqGzs7M7HZP0IhgMOoTFqzIWIrvHQ5vQe2U4NddltCEQ9u7dSzAYJBQK+WYaHV3c3C+HrhJ6t6MHS1D0c9QdvXsCDz1G7+Xo+/Tp4wjLuUtOycnJjg5B6jzV4FtuoVfj0/tRmFwIAdgV3IVE2g7bT+w7G7rZUrnFc7kUst1Cv69CN14hEdUBDLwd/e6W3cx+dTZFlUUR1/WCCy7g008/tfPx6NGjI1oixYueb9rbElAX+urq6oiXjRH6fYju6GtrayNCN+pmdEfYBmK3o3c7er1/gWp14xUj1h19SkqKw/Wq0I0aS0cV970yjY66Fl5N2/r27YsQossqY6FN6N3HVOfb2toaIfR+oZvMzEwyMzMdRX4v0dIdvS706gXrbl4ZLT4P8Mcdf4TbsJonhKltquX2Zbd7bt/Z0M3wrOGey4NJwXa1utkXMfoTTjiBww47zB6fXcerE5/6HAgEWL1ntWfJ5fZlt5OUlMTKppW2cXl73Nucc0e0vp3+6M9je4W+f//+ttC7Bw8EE7rZp+gup7S0lLq6Ok9H7zX1W1eQlJTk2TM2VuhGCOEI3bjRhd4dH1ZuTU0+4Vfcd4uR1/jjikAgwNVXX22PwdJeojl6d09jPYP4OXqv0M3555/PFVdcYS/Tr9vs12ZTMK+ATVWbHC2Z1G8rofdy9NHYUrkFPPTQz3n7Ofp4KwLnnjKX9GTn9UpPTie7T3a7Y/Tu0E13CP1nn33maQ50odfXCyG49tprqcmv8TzmlsotEcZlS80WrvvndVFDZn7ojr69Zm/AgAG2MdPndvA6NsDGndaAdHuq9sQM8XUUI/S0TVawLx29HrrRY/ReIYWUlBRb6HNzc+2esX6hm1hC39LSQlJSkq/ouJera+EX73zsscc4/fTT4zpvhQoZ/eDtHwBQuLfQXufn6HVxVZXBCnfoRpU8srKyuOiiixwTbKyvWN+2Y9CquHx7y9v2IlXCSk9P9w3dxHL0fg7bb3lnHf3McTOZ/8355GflIxDkZ+Uz/5vzyUqPbBocT+hGb16ZnZ0dtXllPOG/eFHPWCAQiBDEhx9+mPyj8z33G541PG7j4sYr/Z1x9Hroxj1KLESahM+3f259aIGiPdFDfB2l1wq9HrpRQr+vHX2sdvSKPn362MsPOuigmKEbKSWVlZURQq+HboLBYNxipH4n3t6BsdCdF+EkvrnlTa577ToK5hXw8lcvA9AQaHDsp4R/wIAB9nguCn3SlcbGRgYNGsSiRYu47LLLIn7/na3vtH0J54Bm2TbAmd7iScWL43H0umDUNNYQCjrvT3pyOnNPmet5TTobowdL7AtvLKT1zlYKbyxk5riZnmYg3tDNeeedx4IFCxg+fLivo483/BcvShT79OnjWQfiV3KZe8rcuI2Ljl/6lxS2NTLsiKPfu3cve/fu9QzdJCUlOUKgrfVtL1WarJfTnNfntOs3Y9FrhX5/cPS6qKsx6r2EXn9QBgwYEDN0A1azrlihm2iZRieWo/fDz+k5nFc4ic2BZh5f8bgl/mEdKa4rdghGVlYW7733Hps2bYoQAbejD4VCXHrppZ73r7KprZexnQO0BjTupq0QO0bvFoyyujKklOSm5Toc9sxxMz2vVWcdvR9eQr9y10rf7e2WWQ01vLHjDa7YfAUF8wp4r/g9z2N21EX7saPRalpZLas9Swd+JZeZ42a2uxQVLf33f3S//b0jjh6s/gB1dXWerdscRkEfpTjcGrSsrqxLXX2vEvovvviCP/7xj4C3o3e3o4fudfRqXBWVcdzir1BuLxQK0a9fv5itbsAS+lpqHUK7Yc8GR+gmWqbR6YjQR3N6Doel3kVJIAn3tQufVmtSa4RgTJ061TO2666MjRZa6ddXi3srgddygrvFE0R39IvWLmLWi7MiBKOptYm+ob4Oh+2H3rxy0dpF/OKLX0BfOO7548h7IK/DYZHq5uqIZYs+XeR7nGAwSGlNKXtq91DTVGPfu9/89zf2Nvpz1xEX7ceitYt4d8e71pcQnqWDRWsXcfuy29lSuYXhWcOZe8pc+7rGa1ziSefW2raxGNtr9tSLQQ1X7NX2P5bQAx1+WXrRq4T+scce4/vf/75d+apQc3Pu61Y37s96Ba2emZQIpKWl2TMKRQvdAGzdtZWivUUOoX2r8C0amhtsRw/exX030Spj43LtYVSRNCC0xy4Da7xTfUSk5Lb/8QrGixtfBOAnr/+EV9a9Qm2rfwuGsw/TOnSHk+LVTtzL0bv/qxdai884fvGmX728CmsKmf3qbEoOKoEfQ3lruVU6CN/DyxZfRt4DeTEFX92XouqiiHWNstFXRAKBAFsrtkIroBWaGmRbGE212CqYV9D2cnaRk5bT7rj97ctupzkpHEILP9p66SBWmCiacfF7Tn1LATnD7VJjPI5eP/73l30faBs9tSOOHjr2svSjVwm96jr/73//2yH0W7ZsITs723PAqu5y9HpnG72JXzRHn5qaSnp6elTXqoS+rLyM1mCrY12zbKahqcGO0ceLeihVjF491OJuweWLL4/t2jXK6sqcopgEzAIxXFMVpbmh6MVuxaK1i7hmyTXW09wMdfV1bNu7zVdcpo6c2vYlCPlZ+Zz/tfPbft4l9HrHNLej93qh6cSTfv23/rvzv1GPB9Y1jBYHd9SBeOXwgL+IBINBGpsbLaHX99Uel6Wbl7Yd34PkQDLVjdVxxe11gSyqLAKlf9qjrdLqZx4uW3wZ4m5B3gOWKXMbl2gvCL9SwC9O/QWpqamkpKTY+c/vZeE+/s5Wq8PXH5b9AYhD6HWPoAl9vM9OPPQqoVejHr733nvU19fbcdCmpiZHRSzsW0f/r83/omBeATVNNRTuLoxYrzt6NUGFX+jm410fA9Ba1xo5wEUAZIu0Qzfxojt6h4hAhKNTDqw9D2lQBLlm0jVtGS58WsGUYNRit8IWgCSgGWiB1kBk2Md9PgDvXPUOhTcWcvTQo+1lXkKvcIdwormuWGEDHSUmVc1VMba0iBYHdwii1/s8EKXdfTBIciAZJA5Hrx/n98t/7/syEghSklJobHFOj+eV3uteu85hFIA2odce7Zw0qwluLIdbVlfGVS9fFfFCiVaPEK0UkJqaSv/+/RFCRH1ZRBw//Bh/8sUnAKwsi6wT8W2eGxb69jw78dCrhF45+vfee4+6ujpHG2X3OOz7IkavuO8/99nuq6XRer2/vul1e70ev1VTzDU0NFDeWO5wGNe9dh1/WP0H7SRcPxrOuHroJh7UQ/nAige4bPFlMR3nlsotnk7JjxbZwuMrHictKY3ctFw7k5869lTfuHaEEwRrvyYshxT0F4aPd35sf75o8UUsWrsoaujGayAztcxXMEUwatjAveytbdZcPVl942/ZpJ+f5/UAzxweTApS01jjGVYJBAIMTBtoCb22b2pKW1PH7Xu3+6ZJIqlp9G/rrqf38RWPR4Z+Qq7/QHVjNYvWLorLPDS2RIalotUjRIv5p6Wl2UYv2ssi4vgpWHmtwvr6yOpHfDshRpTKm4hZcd8Reo3Qt7a2sn37dkKhEKtWraKkpISMjAxb8Pwc/b4I3dS3hCuGw6EHgN9//Ht7vTt0A1C8u5h15escDuOxFY/RgNYk0VUYSUpKQkgRV+hm0dpF5D2Qh7hbcN0/rwOgNhBfz73hWcM9nVJumv+1VC1V6prrmH3sbAAmDp/omzbdXbWdILajJ+gtwovWLmL+6vn29111u5j96mw+KfnEXqZi0Iu/skYOrWiusDOqO0bv9UITCFpkC7cvu53rXrsuwgle+dKVXPXyVY5ld/z7DgDOPPTMuF+Q6vx8rwd4OnoRFI64/5UvXWlX+P7zq3/S2tpKKBAiM9WqkwmKIPWyrfHCkGzPCebiTi9YwukZ3/cI3Sjxjtc8FFUWOYTV7wWRk5YTNeaflpZmx+ejvSwiji+wGhmEG3c1BBqY9aJzzCMVYnU3Wf77+X+PWXHfEXqN0JeVldHU1MTJJ59Ma2sry5cvt0Mh0LOO3tHyIyz0umtyh24AduzeQWvAGYO3Dqx91t5dQRGkWTYjWyWvrX+NtaVrfSvJFq1dxJUvXUlZXZkzfdE7gwLOIqe7ovf3Z/w+Zkatbapl8QZLYDdWb4y7otc+97DQiyThWfSd8/ocGqUWVghYv/nKhrYpFt7a8hazX51NjbScaYtosQXggx0fAPDyxpcpmFcAYL/QwBJ5JWBFlUU8vuJxz9Y47tBGfXI9DIK/lv6VtKQ0+iRHH1JCv85R6wk8cngzzY7vTa1NtvDXttSyvWo7jU2NHJx7MOnJ6VadinacU0edGvU+5qbler78zhzd1nvaNwzj4ejV9rp5iIUu2H5xeCBq09CpU6eSPTY7aqXz8KzhjvOySQNUg6eQVWrVXyZVLVaIzi303TUMQq8RehWfnzJlCmAJf1pamh2ndwv96aefzuzZs2P2gOwoDqEPaP/Dz5PumrwcfUtti/fd8xB65TBV6KapsQkC3s3XwBKOplatVkgd00foRfjAsYqcbpfvx+4mqxfwS5tealdFrx66SU5OjkjHorWLrJeX7nLDn8sb2qZJmP+/+ZYAhNq2US2GHlrxkL2sqLKIyxdfzn+2/IfCGwvJz8qPEAQ/gYggCbgaOBhbdK+ddK19rXLTcn3b5EeNXYfPz9HvIFquF1gVsa3wya5PPGP9y4qWMf+b8z1LaOnJ6fz+jN8za/wsxz2WSB5f8TjibkHBvAI77h6BR4weLPed90Aely2+jKLKIvok9yEo/Eul6n4VzCvg8sWX22FB/fqV13lPjaGu56k/OpXXBr3mW+mcnpzOmaPPZMHqBR4rsfOy+6VV21TLlxXWxPVG6LsYFZ8/+ui2SjddON2hm1NPPZU//OEPdBeO0Im6C1pevO3E2+zPuqO3O0E14l3Rpgt9ttNh2sdvaftNr0qyCOFQmc5jNrWgCLLw/IXIO6WjyOnXQkF3+X7ObEA/66XbFHCOJa5aWPiKp+boG2mMWG2fp37dwtdBJLVd/J11VqsJO4OGr2lZXVlbM8PwMZSARX0BdYDaplqe/+x5+1rtvmU3vz/j9wzPGs6Wyi3cvuz2mE0EAfv8QimhiGWeCCyBilIZW7y3mJnjZrL7lt08c/4zjpdRWlIaly++nPkr5/u+9Ioqi6hqqIroOSwQHDfquHCC25YnB5KpqK9oK2ECe5us+QSilXzK6socHdjK68q5ZtI19nMaq4NVtJKSOtfHVjzmvY3eV9HLK4av58pyZ0WtEfpOohz91772NUfvQz9H3934OvowF427yP7s5eiBmEKfn+1ymOr4mtBDpLBHuK2RwDeBwc7FoWCIBectiBD3aM0udfyK1MePPD78Ax7nF40kbEffJy1SAOzz1F+G4esghcd10hy9TTBymURGbWkUrfQSDb13pFerDxVbL6os8v+NcDqbgtpLM1quD2A5evd2rpej+8W98PyF1DXX2aURv34FiqbWJjJCGY46nIXnL+T1771OMClITm6OvTwzJdPzeC2yhbz0vLhCOeB8KUPsDlbRXtzqXH2JJfRJWC9SZaLC19cIfSdRjn7w4MEMHmwplmrFApGOvqPEO8CTp6N39c5Ux5qzzBr3Ymf9Tj7a9VHbNsmRLWdUJU9SUpIdTrBRWtDs/C2JJOmeJLstckV9hfOgScBRzn1y03J56pynHCIfT7NLHb+mbR9Xfmyltb1zRoSwhX54znD7PuQ9kEfeA3ltafISbi9R8xL6JNf/MEWVRZ6tTdKT07lm0jVxi5Ebdc283KWKrUOUEFH4vBz1ObEcfYv2WeG6ZrNenOV4tmP1J/CivK48os17ZmYmH37wIVv/vNVe7hdiAUuMzxx9ZtwvU/VSBiJi/kERtJ/TaK181HbRyMi2esMmpySTnupRnxHEeob0Zy1ghL7TbNu2jQEDBpCcnGwLfbTK2I4Qq+ee/hJ4bt1zbTt6iM3f1/+9TTjDgvPhzg/57Yrf2ts0i2aSA8mO2OPD5z8MwO9+9zvA5Vo8QjcK5ZgiOjRp5Kbl8sz5zyDvlOy+ZbcjBh5PRvdySF49c7cHt8OPgPZqYwgrpNUCGyo3OIrtDvflEbrxXOYK3Ti28yhNeTm8tKQ0jh9+PIU3FnbI2asmgH5xYjeOXsd6OoN4PmcRadKFXj9UgLbnR1jPi/5sdyRsFRABT0N09NFHk56eHrP3LVilzwWrF8RfF+JK68xxM+08op57lW/PHB3ZAio5kByztJKenM6hww4FrJJUXVNd5EZJWG5evz9JRug7zfbt222B14W+Kx39nNfn+Nbiu18CNc2a+wvfhWBSm3rcsuyWtmOFBUcGJc0BrcVE0HJ1FfUVLDx/IYU3FvLdKd9FSkm/E/vZFVF2ZtZDNx2IJvj1yIxXiCTSroyL1iV+eNZwa2iE9qZRq4xtFs3+23mJeryOPorQe1FWV2bdg7tFu8RIoZoAxkurdLXE0ut/XC81vbTheEZatX10gjgEXy+ldaQXp7slintMm2i9bwE7xt/ekoQ7rX5t5J//7HlHiTM3LTfmROO5abnMGj+LT6rCzXVDPqWtEcAhtD1HSRBICRih7yz6nLBqTkkV805JSYl7omw/7BYdHqgxShwPk9st4YwT661AbMFJxtkaIbyf2125Xyqq4iqao4+X2qZaR5tg1U68PcQayjbeonjENpqjjyrEsUI34c9JaWErH6ej96MjAg/W+TW0NLRLyCJaomjnJ4JtYq5KgY+teIyiyiJy0nKsVjR+jl59dx1eueO5p8y1etR2EHdoL1YJUYUOo4V1vBAIiiqL7Ge3YF6B78ukrK6MOa/PYe4pc2m9s5W+ob4RzWLd1DXX8fxnz9MUCteJ+NUzTQDOxvE85WbmGqHvLHv27LHbxOuOPisriyFDhsR8U8ei3SPNeQhLK5ob05Oj8k8STqHXMp2eUXwzSRcIPTidmFc78XhQLWjc7n7R2kWeRfG+IavlkRKy/Kx857AJ0DGh93L0aqCz1OTI7Tsg9B0lWi9TL9KT05l91GznNdHOTwasa3rxERdT1VDVZgCwRK2ivsI/Rg9tjl5DueOZ42aSmeJfqRLPi1sPqfiFggTCETpsT0nC3cdBveSioZdi4wlP1TbVWoZPVcbGalAQfo6G5QxjQPYAI/Sdpby83B7yQBf6O++8k+eeey7arnHR7hilLjAiyjJwxop9hF5Pg29aXK1uOtoaRKejblXh7pnpNdwvWA5O3ilZcN4C8rPy2VK5hSUbljBr/Ky2is4QbU0D4xT6nL45EcvU5zpRF7kuZH0PZnS90nfmfqghFx79xqPOTkV6iSV8/5///HlnP4kwLdI1BlI4OcmBZOsFq8f5sUIneqe0aO7at928hi7a8Y4t356hNjr6rKpSbDznYKOE3qPvSVAE7Tq108dYM7MNzBpoj2PVHfQKoW9tbWXPnj32/KR66GbEiBFMmjSp07/R7hilW9y1z3YRWxGn0Etk9M4oWqubYFKwU61BYhFRKRgFvWdmtOF+vSq7F6xewNxT5loiqbunOIV+9627rWvgcR88K2NTgOvgu9/5boQwq+8dFezOvDRbZatdOa4quAXCGZdXJUfh0aM6jD7TFgGczRtdjj4jlOGokPfLA7lpuTFDLMmBZMf4O6NyRnlex5rGGkcJ0N1yK1onqs7QIluoaqiK6/i5abmkZoY7nbgcfXpyOgvOW2A3Pjhi8BHWZqGQEfrOUlVVhZTSFnrd0XcWe9zvaG2ZvfAIGQSC1peUUIrTpfQBDgr/ecWLNfw6oyQHkgklhZe1WM07VWuQaGKvt+ppTyZKCiRx7aRr43ZbsYg2J+ic1+dYIhPlJagQCBrvtuKswWAQIayhElJDqZH7elXGAvkj81lauNSzQ5BqD64PiRAP+Vn5vvchNy03ppB5iezwrOFORx/+rJ4zL9T4NgCPffMxZ/NGl6N3i7dfu3TV0Ssa+su+qLKIZZuXeb74vBoE6C23Fpy3wDMN0cZZipem1qaYL2N1vg99K9yDWsuGuWm5ET3H9UHy+vTp45iUvSvpFUKvJnhWoZsRI0Zw4YUXMn369E4d16vteNyuziX0+Vn5HH7Q4QCkhdKcLiU5CNdgdVzSXZWPmDW1NpEcSHa0T//exO85QjeNrY32JBbR4pRPn/s0u2/Z7ZuJ/GhsaWTJhiVxj00SjVhzgpbVlXHm6DMJpWu5yufa5KTl2OEJNUrlzHEzufPkO9s2UtcpiYgKSDVmS7RBrpTwyDulQ/SVSLufDXV+0YQylpB5jesz95S5baNyaqGby4+83LPiNBQMceLIE+3vqq+HLdIuR++eXATwHfLXr7K2Iw482hDNfn0z4hlnKTmQHHOMoYhWTRqOIY7TU63rpT2Sdc2RzSzV/QmFQvzjH//g/fffj/r7HaVXCP2ePXsAbEefnJzMc889x4QJEzp1XC+HKbHmCY0Zz9PEOj8rn8IbCxmaNRTAnuZPz9wOXL3pvNjbtNduLVB4YyFLNiyhsdU5mBdYIun3UsrPyne4j/YMKgVO0Wuv2Ks4pt6tPlo4aMmGJZw69lTtAN7bVTdW85dP/0IoFHIMTXzu4edaH9z1I18Hjmj7KpEsWL3A9/66nasu+s0/b3aIv1sM45na0b2Nfn3cFdszx83koiMuss9Lne9vz/gtT5/7tMPlqlYs4waOa7uEYaG3X0DaywKcQwyollQQOfGHSovXb2anZntex1hEqxPz6psxc9xMZo2f5btPUAR5+tynqflpTYfcv8rD6nzveOsOOA2rdU0YrxeU7ug72yAkGr1C6N2OvquI5jCjdo8Gh6NXx1FOs7yh3NGRZOa4mc6HL7lt32iOSH+otlRucQqYq2esn8t0ozLRM+c/E9Mh6aLnV2nWJ7lPRJhJxTHb061+S+UWVu7Wxg3xuSxqyNuUlBSH0NuVkK4cIY4REUM/qJd7e+cnVUSbvjGeqR39hh3warZ6bP6xAHztoK/Z12TC/AkA7L5lN/JO6WjFovfYVp/VyyWYHIxqLmJNCq7Gx9F/s73NIxUdabe/ZMMSz+UC4RjKo71p8rrvWyq3wDGAa0Rnt2Z4zUHcHfQqoVeOvqtoVy28G60yVj20O2p3ANawuO6M6yh6hvUplBJi9lH+bdj1h2p41nDvCscwKr4cbZJwHbe7j/Wi8HKrz5z/DDU/reGpc57y/O32dKsfnjWcXY272hZEEaQtlVsiHL36nJqS6kiLX0y2vK48ronVu5Nok2Eo1HmtK19Hk7Ra2myt2erbj8FL6MG6f0nJSTEVo72tzzoi2B2dfckvbRIZV6WyF373Pd5WQ3ropjvpFULvDt10BYvWLqKqoarjB9Ba2KiHdk3JGsc6aKtsVJk6KIK20F8z+Roe/cajvkVNt6MOJfuPYKiKntGcpBuvWHQ00fNzqyqG6x6ZMV7RUBl/cK5mvaMI/fCs4YRCIc8J2tNT0u00zj1lbtTKz3jcd3cSrZ5AoYSklVZHKdLPfQcCAc/PEJ4gPEZIvb3C7TdxyykjTolriOb24Jc2d1gx3iabAuF732MNmKZYVboKgEXrFsU9iXpHiH8+uQOY7gjdRIzZHiYgAlErbNo2tP4dlHmQPd2cPSGGS4T1UFCLbCEQCtBKKyePOhmA35/xe2a/Otvh7rwc9ceTPubBZx+M+I2umJ9SxUE7gqrUVulXJZmctBzPEFhuWi59Q30jpn8rO7mMOb+yBoDzEyR1rrfPu90RE1WCqP6rNHmFi7p6Ps+OsGjtIgIi4Jk+XdAclbGuXsBeLwo/Rw+Q/bVsKqorfNPUkeuinhm/6fy6krmnzI2ZT7zSFM91dhPPeS1au4hFn4WFPYijnqNHZpgSQswQQqwXQmwUQtzqs82FQoh1QojPhBB/0Za3CCFWhf9e6aqEx0NZWRmTJ0/mww8/JC0tzR7ZsbNEG9ulVbbGdAMCwdQRUwHI7Wu58duX3e7dtt7rN5KsF4kq7sVTiQcwfeR0+3NmWmaPhRzc+IUgwDsOrrdC0R3V5ZMub9swXMmtT96hn6s7Ru8Wer+wkT4XbE/RnpdQRKsbgf2ceQlVNKF/+BcPk/71SPcNnZvndF+VjOLNJ+40taelk98xvM7r9mW3t82boIYpjlHP0VFiOnohRBB4BKsOuRhYLoR4RUq5TttmNHAbcLyUco8QQh8Ksk5KOaFrkx0fa9asYfny5Qgh7LbznUVlMj/ys/Itx6i9yUfljOKtzW/Z8V6J5L/b/wu0hQy2VG7x7o7vRfiu6XG9eBy1nnGvnXwtv7rzVzF+aN/gF4Iorytn4fkL43Z7atx+gLe/+3bU5rOhUIjW1raSl7vJpV+a9I5JPUV7XkLqfIJJQVoCbbOS+QmVHq5xC/2+dN/dRUdKnt113lsqtzgGNXMs72LiCd1MBjZKKTcBCCGeBc4B1mnbfB94REq5B0BKWdLVCe0IJSVWMqSUXRa2iVVBqMYmKbyx0F7mNdSqauqoMuLwrOEUBcKlBL0TlVcoKGzSdEeq4zezvZ6JHV3de5jhWcM9S0gqDh5vhlIVrE1NTTErt0KhkKNzitvRR0tTT9Oel5A6n2Pzj2XlVyupC9TZZsTrukZz9NC5EN2BTHec9/Cs4RQFw89Y0Lm8q4kndDME2Kp9Lyai0RBjgDFCiP8IIT4SQszQ1qUKIVaEl5/r9QNCiNnhbVaUlpa2J/1RUUIPXVcRG+tt69Vzz3Of8JVXgjv3lLkRTfzSk9O5+qirI4qNwRTrqfASs2hj4usZd38S+ngrruJBTbsYj9Dr10AJon4/uipNXU28LTqg7bzG9B/DjLEzyErPihoeiSX0hq5j7ilzSQmFm1VqQ0d3xzPWVa1ukoDRwHTgEuAJIUR2eF2+lHIScCkwTwhxsHtnKeV8KeUkKeWk/v37d1GSnELfVY4+nretO87muU/4yuu9M+0YeqAt5qkPUqXiitNGTQO8xSxak7v9NRO3J3YaCxW+iSX07hi9Ku3o96Onm0/60Z6XkP4CS0pK8i0FKqKFbgxdy8xxM7nx+ButL8HO1XPEIh5btw0Ypn0fGl6mUwz8V0rZBGwWQnyJJfzLpZTbAKSUm4QQ7wBHAl91NuHxoJcOusrRzz1lLpctvizmdrqL96rtDwaDtNDCe1vfo2BeAXNPmcthAw/jTd7kxJEn8s6N79jbuouNPyz6IW/ztqeYRWtyt7+GbqDrisbxOvoLL7yQpqa2VlNCCJKTkx1CuL+GKdoTM9aFPjk5OeZ931/NQKIyY+wM7ud+5p01jzlz5nTb78ST25cDo4UQI7AE/mIsd67zEpaTf1oIkYcVytkkhOgH1EopG8LLjwce6KrEx6KkpIThw4dTXFxsj0XfWWaOm8mc1+fE7Pmqu3h3xsxJy6EyWGmtDLQ1q5q2x3LqsTKjmv7Qy51Fiy3vr6GbriReR3/ddddFLIvH8e4vxPsS0oU+LS0tZg9M/Rlxt6M3dD3q/vR4z1gpZTNwPbAU+Bx4Xkr5mRDiHiHE2eHNlgJlQoh1wNvAzVLKMuBQYIUQYnV4+a/01jrdTUlJCQcffDCLFy/m+uuv77Ljxhogya9trmpq1TfUl2bCw8GG70BtUy0fFH8A+Fey2scPC72XmEUr1vcGoY/X0XvhdvSJgF7JfPPNN/Pkk09G3d44+n2Lek67u2dsXLldSrkEWOJa9nPts8SazvlHrm0+AMbRQ5SUlDBx4kTOOeecDh9Db8GihjworysnJy2HtKQ0+7NaHk/TK8e4M1peqmqyetrGEmE1vLLXwxGtWP+f//zH3i5RM7EReie6ox87dixjx46Nur2J0e9b9tVYN4lp68KUlpbSmcpdd49NPVxTVldGenI6C89f2O44rl9Tyqy0LCqpjCn0hx9+OEOHDvWtYPYr1u/PMfquIt7QjRcHUugmXtytiWJhHP2+ZciQIeTl5TFmzJhu/Z2EDcI1NjZSUVFhTwjeEWK1me9oLzZHsyqtKeUpo04BYPve7Y5xvt3jX5x++uls3brVDuHEiwndRCeeysoDDSP0+zd5eXmUlpZy9NFHd+vvJKzQqxY37RF6NVuUEthYEwdDx3qxzRw3k5uOv8n6ojWlPHLwkQCs3LXSsx18Z+kNmbgzjj7RQzfxYEI3iUnCCr1qQx+v0Ht1NIpnGriO9mKbMcbqU3blUVfaHVhUZmzBOYZJV41/0RtCN/369SMlJaVDItWnTx/HMAqJgHH0BkjgGH17Hb3fbFHR6EwvNpWJ4pn8Arpm/IveELq5/vrrOeWUUzo0W8+CBQu6fHKansY9tEMsTPPKxCQxczttjj7eytiOCGlnerEpodUF185kHvmrK8a/6A1urX///h2ugJ84cWIXp6bnycjIICcnh/z8+KZyNKGbxCRhhX737t2AVdkRD34djfxwz6faXtyjJerLkpKS2trZ03XjX/SG0I3BSWpqKjt27OiQozdCnzgkbNmsoqICgKysrLi2j3dWGega4VWZyGuWo5NHndwtY6z0htCNIZJQKBR3KMsIfWKSsLm9oqKCzMzMuB9WvaNRNGcfbYjX9uDl6FVav3bQ11h649JOHd8LI/SGWJjQTWKS0I4+Ozu7XfuoYQrcc0gq1LyqXemuvRx9d4mwycSGWBhHn5gYofdgX4xFHs3Rd5fQG0dviIUR+sTECL0HXmORzxo/i9uX3e7bW7W9eLn37nb0RugNsTClvsQkYXN7RUVF3E3KdBatXeQYhjg3LZczR5/JgtUL7Hb2XTFbe7TQTXf1zjSZ2BAL044+MUnYO9kRR79o7SKufOnKiMHLHlvxmO+sTR3FhG4M+yMmdJOYJLTQt7eX4+3LbqeptSn2hmE601s1NTUVIYSjy70J3Rh6GlPqS0wSMre3tLRQWVnZbkffXuHuTG/Vfv36sXTpUo455hh72b5sdWOE3uCFcfSJSULm9qoqawKP9gj9orWLCIgALbLFc71AOMa+6YpWOKeddprj+74M3ZhMbPDCPCOJSUKGblSv2HiFXo1c6SfyoWCIayZd0y29VXW6uzLWhG4MsTChm8QkIXN7e4U+2gQjuWm5/P6M33e5qHvR3Y7ehG4MsTCOPjFJyNzeHqFftHaR75AHAsHuW3Z3Ycqisy8rY00mNnhhnpHEpFeHblTIxo+uGBq4PZhWN4aeRi/1mXb0iUNC3sl4hT5ayKarhzyIBxO6MfQ06hkUQnRo8hbD/kmvFvpoo1R2R2VrLLq7MlbPvKZYbvBCPRfm+UgsElbohRBkZmZ6rl+0dhF5D/hPSNLZSUU6yqhRozjhhBOYMGFCt/1Gd5caDAc2qtRnhD6xSMjcrsai94oxqri8X8hGIPZ5yEaRlZXF+++/362/EQwGaW5uNkJv8MQ4+sQkYR29X9gmWlwerAnBe8LN7yvUy88IvcELI/SJSa8T+ljDHPhNOpIomIxsiIYJ3SQmvU7oozWZ7ImWNvsaE6M3REM9H6ZpZWKRkHdzz549viNX+k0CnpuW2yMtbfY1JnRjiIYp8SUmCZnbozl6fRLwLZVbGJ41vEsm+z5QMI7NEA0TuklMep3QgyX2vUXY3QSDQePmDb4YR5+YxGXrhBAzhBDrhRAbhRC3+mxzoRBinRDiMyHEX7Tls4QQG8J/s7oq4X40NzdTXV0d1/AHBfMKumwO2AOFQCBghN7gixH6xCRmjhdCBIFHgNOAYmC5EOIVKeU6bZvRwG3A8VLKPUKIAeHlOcCdwCRAAivD++7p+lOxiGcsendb+q6YA/ZAIRgMmkxs8MWEbhKTeBz9ZGCjlHKTlLIReBY4x7XN94FHlIBLKUvCy08H3pBSlofXvQHM6JqkexPP8Adebek7OwfsgYIJ3RiiYRx9YhKP0A8Btmrfi8PLdMYAY4QQ/xFCfCSEmNGOfRFCzBZCrBBCrCgtLY0/9R7EI/R+bek7MwfsgYIJ3RiiYYQ+MemqphdJwGhgOnAJ8IQQIjvenaWU86WUk6SUk/r379+phMQj9H5t6ff1sMQ9gXH0hmiYVlmJSTx3cxswTPs+NLxMpxh4RUrZJKXcDHyJJfzx7NulRBN6VQFbVFmEwDkEa2/oLAUmRm+IjhndNDGJR+iXA6OFECOEECHgYuAV1zYvYbl5hBB5WKGcTcBS4OtCiH5CiH7A18PLug0/oVcVsGpoYom0xb675oDdHzGhG0MsjBlIPGLmeCllsxDieiyBDgJPSSk/E0LcA6yQUr5Cm6CvA1qAm6WUZQBCiHuxXhYA90gpy7vjRBR+Qu9VASuR5GflU3hjYXcmab/ChG4MsTBCn3jEleOllEuAJa5lP9c+S+BH4T/3vk8BT3UumfGjxqLPyMhwLO/NFbA6JhMbYhEIBMwzkmAkXI1LRUUFWVlZEZVJvbkCVseEbgyxMGYg8Ug4od+zZ49nRazXYGa9pQJWx4RuDLEwQp94JJzQV1RUeI5cOXPcTOZ/cz75WfkIRK+qgNUxmdgQi0AgYJpXJhgJZ+1ijVzZ24TdjQndGGJhzEDikXCvbS+h760DmHlhQjeGWBihTzwSLsdXV1fTt29f+3tvHsDMi2AwiNVIymDwxrS6STwSTugbGhpIS0uzv0cbwKw3Cv3s2bNpaWnp6WQY9mOMo088Ek7o6+vrSUlJsb+b9vNOLr300p5OgmE/xwh94pFwMfr6+npSU1Pt737t5HPScvZVkgyGAwoTukk8EkropZQRQj/3lLkkB5Ijtq1urO7VlbIGgx/G0SceCSX0TU1NAI7QzcxxM8lMyYzYtrGlsVdMNGIwtJdgMGja0ScYCRWjr6+vB3A4eoDyOu9x1HprnN5giMasWbMoKCjo6WQYupBeIfTDs4bbwxO7lxsMBic//elPezoJhi4mocpnDQ0NQKTQm3FuDAZDbyahhF45ej1GD2acG4PB0LvpFaEbMOPcGAyG3ktCOnovoTcYDIbeSkIJvYrRu0M3BoPB0JtJKKE3jt5gMBgiMUJvMBgMCU5CCb1f80qDwWDozSSU0Ps1rzQYDIbeTEIKvXH0BoPB0EZCCb0J3RgMBkMkCSX0JnRjMBgMkSSk0BtHbzAYDG0kpND/bf3fKJhXgLhbkHRPEuJuQcG8AjPRiMFg6JUk1Fg3DQ0NJKckc/U/rrYnBG+R1kTYRZVFzH51NoAZ88ZgMPQqEs7RN4tmW+Td1DbVmlmlDAZDryPhhF4GZdRtzKxSBoOht5FQQt/Q0EAwFH1SYzOrlMFg6G3EJfRCiBlCiPVCiI1CiFs91l8hhCgVQqwK/31PW9eiLX+lKxPvpr6+ngFZAyJmk1KYWaUMBkNvJKbQCyGCwCPAGcBhwCVCiMM8Nn1OSjkh/PdHbXmdtvzsrkm2N/X19fTP7G/PJgUQFJbDN7NKGQyG3ko8rW4mAxullJsAhBDPAucA67ozYR2hvr6e1NRUM5uUwWAwaMQTuhkCbNW+F4eXufmWEGKNEOIFIcQwbXmqEGKFEOIjIcS5Xj8ghJgd3mZFaWlp3Il309DQENFZatHaRRTMKyBwd8C0pTcYDL2SrqqMfRUokFIeAbwBLNDW5UspJwGXAvOEEAe7d5ZSzpdSTpJSTurfv3+HE1FfX+8Y/mDR2kXMfnU2RZVFSKTdlt6IvcFg6E3EI/TbAN2hDw0vs5FSlkkpG8Jf/wgcpa3bFv6/CXgHOLIT6Y2KCt0obl92e0SbetOW3mAw9DbiEfrlwGghxAghRAi4GHC0nhFCDNK+ng18Hl7eTwiREv6cBxxPN8b23aEbvzbzpi29wWDoTcSsjJVSNgshrgeWAkHgKSnlZ0KIe4AVUspXgBuEEGcDzUA5cEV490OBPwghWrFeKr+SUnab0Lsd/fCs4RRVFkVsZ9rSGwyG3kRcY91IKZcAS1zLfq59vg24zWO/D4BxnUxj3Lhj9HNPmcvsV2c7wjemLb3BYOhtJFTPWLejnzlupt2mXiBMW3qDwdArSbjRK93NK02beoPB0NtJGEcvpYwI3RgMBoMhgYS+ubmZ1tZWM7uUwWAwuEgYoVcTg6/bs870hDUYDAaNhInRq2kEX/jyBZoymwAzq5TBYDBAAjn6lJQUss7IomlQk2O56QlrMBh6Ownj6DMyMqiaUuW5zvSENRgMvZmEEXowPWENhs7S1NREcXGxHQo17H+kpqYydOhQkpOT494noYTe9IQ1GDpHcXExGRkZFBQUIITo6eQYXEgpKSsro7i4mBEjRsS9X8LE6MH0hDUYOkt9fT25ublG5PdThBDk5ua2u8SVUI4eTE9Yg6GzGJHfv+nI/UkoR28wGAyGSIzQGwyGDtPVU3WWlZUxYcIEJkyYwEEHHcSQIUPs742NjVH3XbFiBTfccEPM3zjuuOM6lcYDkYQL3RgMhn2DmqpTNX7oig6Kubm5rFq1CoC77rqLvn378uMf/9he39zcTFKSt2xNmjSJSZMmxfyNDz74oENpO5Axjt5gMHSIfTVV5xVXXME111zDlClTuOWWW/j444859thjOfLIIznuuONYv349AO+88w5nnXUWYL0krrrqKqZPn87IkSN58MEH7eP17dvX3n769Ol8+9vf5pBDDmHmzJlIKQFYsmQJhxxyCEcddRQ33HCDfVydwsJCpk6dysSJE5k4caLjBXL//fczbtw4xo8fz6233grAxo0bOfXUUxk/fjwTJ07kq6++6tLrFA3j6A0GQ4fYl1N1FhcX88EHHxAMBqmqquL9998nKSmJN998k5/+9Kf8/e9/j9jniy++4O2336a6upqxY8dy7bXXRrQ9/+STT/jss88YPHgwxx9/PP/5z3+YNGkSV199Ne+99x4jRozgkksu8UzTgAEDeOONN0hNTWXDhg1ccsklrFixgtdff52XX36Z//73v6Snp1NeXg7AzJkzufXWWznvvPOor6+ntbW1y6+TH0boDQZDh9iXHRQvuOACgsEgAJWVlcyaNYsNGzYghKCpqclzn2984xukpKSQkpLCgAED2LVrF0OHDnVsM3nyZHvZhAkTKCwspG/fvowcOdJup37JJZcwf/78iOM3NTVx/fXXs2rVKoLBIF9++SUAb775JldeeSXp6ekA5OTkUF1dzbZt2zjvvPMA9vkouyZ0YzAYOsTcU+aSnpzuWNZdHRT79Oljf/7Zz37GSSedxKeffsqrr77q26Zcn5siGAzS3NzcoW38+N3vfsfAgQNZvXo1K1asiFlZ3JMYoTcYDB2ipzooVlZWMmTIEAD+9Kc/dfnxx44dy6ZNmygsLATgueee803HoEGDCAQCLFy4kJaWFgBOO+00nn76aWprrfqL8vJyMjIyGDp0KC+99BJgDauu1u8LEkrou7qpl8FgiM7McTMpvLGQ1jtbKbyxcJ90Vrzlllu47bbbOPLII9vlwOMlLS2NRx99lBkzZnDUUUeRkZFBVlZWxHbXXXcdCxYsYPz48XzxxRd2qWPGjBmcffbZTJo0iQkTJvDrX/8agIULF/Lggw9yxBFHcNxxx7Fz584uT7sfQtUy7y9MmjRJrlixot37uZt6gVWMNEMgGAzx8/nnn3PooYf2dDJ6nJqaGvr27YuUkh/84AeMHj2aH/7whz2dLBuv+ySEWCml9GxfmjCOfl819TIYDInPE088wYQJEzj88MOprKzk6quv7ukkdYqEaXWzL5t6GQyGxOaHP/zhfuXgO0vCOHq/Jl1mLHqDwdDbSRih35dNvQwGg+FAImGE3oxFbzAYDN4kTIwezFj0BoPB4EXCOHqDwXDgc9JJJ7F06VLHsnnz5nHttdf67jN9+nRUk+wzzzyTioqKiG3uuusuuz27Hy+99BLr1q2zv//85z/nzTffbEfq91+M0BsMhv2GSy65hGeffdax7Nlnn/UdWMzNkiVLyM7O7tBvu4X+nnvu4dRTT+3QsfY3Eip0YzAYuo4bb7zRHhu+q5gwYQLz5s3zXf/tb3+bO+64g8bGRkKhEIWFhWzfvp2pU6dy7bXXsnz5curq6vj2t7/N3XffHbF/QUEBK1asIC8vj7lz57JgwQIGDBjAsGHDOOqoowCrjfz8+fNpbGxk1KhRLFy4kFWrVvHKK6/w7rvvct999/H3v/+de++9l7POOotvf/vbLFu2jB//+Mc0Nzdz9NFH89hjj5GSkkJBQQGzZs3i1Vdfpampib/97W8ccsghjjQVFhZy+eWXs3fvXgAefvhhe/KT+++/n2eeeYZAIMAZZ5zBr371KzZu3Mg111xDaWkpwWCQv/3tbxx88MGduu5xOXohxAwhxHohxEYhxK0e668QQpQKIVaF/76nrZslhNgQ/pvVqdQaDIaEJicnh8mTJ/P6668Dlpu/8MILEUIwd+5cVqxYwZo1a3j33XdZs2aN73FWrlzJs88+y6pVq1iyZAnLly+3151//vksX76c1atXc+ihh/Lkk09y3HHHcfbZZ/P//t//Y9WqVQ5hra+v54orruC5555j7dq1NDc389hjj9nr8/Ly+N///se1117rGR5Swxn/73//47nnnrNnwdKHM169ejW33HILYA1n/IMf/IDVq1fzwQcfMGjQoM5dVOJw9EKIIPAIcBpQDCwXQrwipVzn2vQ5KeX1rn1zgDuBSYAEVob33dPplBsMhm4lmvPuTlT45pxzzuHZZ5/lySefBOD5559n/vz5NDc3s2PHDtatW8cRRxzheYz333+f8847zx4q+Oyzz7bXffrpp9xxxx1UVFRQU1PD6aefHjU969evZ8SIEYwZMwaAWbNm8cgjj3DjjTcC1osD4KijjmLx4sUR++8PwxnH4+gnAxullJuklI3As8A5cR7/dOANKWV5WNzfAGZ0LKnRMQOaGQyJwTnnnMOyZcv43//+R21tLUcddRSbN2/m17/+NcuWLWPNmjV84xvf8B2eOBZXXHEFDz/8MGvXruXOO+/s8HEUaqhjv2GO94fhjOMR+iHAVu17cXiZm28JIdYIIV4QQgxrz75CiNlCiBVCiBWlpaVxJr0NNaBZUWUREmnPXWnE3mA48Ojbty8nnXQSV111lV0JW1VVRZ8+fcjKymLXrl12aMePadOm8dJLL1FXV0d1dTWvvvqqva66uppBgwbR1NTEokVtGpGRkUF1dXXEscaOHUthYSEbN24ErFEoTzzxxLjPZ38YzrirWt28ChRIKY/Acu0L2rOzlHK+lHKSlHJS//792/3jZkAzgyGxuOSSS1i9erUt9OPHj+fII4/kkEMO4dJLL+X444+Puv/EiRO56KKLGD9+PGeccQZHH320ve7ee+9lypQpHH/88Y6K04svvpj/9//+H0ceeaRjPtfU1FSefvppLrjgAsaNG0cgEOCaa66J+1z2h+GMYw5TLIQ4FrhLSnl6+PttAFLKX/psHwTKpZRZQohLgOlSyqvD6/4AvCOl/Kvf73VkmOLA3QEkkechELTeue/mZTQYDnTMMMUHBt0xTPFyYLQQYoQQIgRcDLzi+gG9Wvhs4PPw56XA14UQ/YQQ/YCvh5d1KWZAM4PBYPAnptBLKZuB67EE+nPgeSnlZ0KIe4QQqir7BiHEZ0KI1cANwBXhfcuBe7FeFsuBe8LLuhQzoJnBYDD4E1eHKSnlEmCJa9nPtc+3Abf57PsU8FQn0hgTNb7N7ctuZ0vlFoZnDWfuKXPNuDcGQweQUiKE6OlkGHzoyKyACdMz1gxoZjB0ntTUVMrKysjNzTVivx8ipaSsrKzd7esTRugNBkPnGTp0KMXFxXSkmbNh35CamsrQoUPbtY8ReoPBYJOcnMyIESN6OhmGLsaMXmkwGAwJjhF6g8FgSHCM0BsMBkOCE7Nn7L5GCFEKFHXiEHnA7i5KzoGCOefegTnn3kFHzzlfSuk5hsx+J/SdRQixwq8bcKJizrl3YM65d9Ad52xCNwaDwZDgGKE3GAyGBCcRhX5+TyegBzDn3Dsw59w76PJzTrgYvcFgMBicJKKjNxgMBoOGEXqDwWBIcBJG6IUQM4QQ64UQG4UQt/Z0eroLIUShEGKtEGKVEGJFeFmOEOINIcSG8P9+PZ3OziKEeEoIUSKE+FRb5nmewuLB8L1fI4SY2HMp7zg+53yXEGJb+H6vEkKcqa27LXzO64UQp/dMqjuOEGKYEOJtIcS68HwWc8LLE/0++513991rKeUB/wcEga+AkUAIWA0c1tPp6qZzLQTyXMseAG4Nf74VuL+n09kF5zkNmAh8Gus8gTOB1wEBHAP8t6fT34XnfBfwY49tDws/5ynAiPDzH+zpc2jn+Q4CJoY/ZwBfhs8r0e+z33l3271OFEc/GdgopdwkpWwEngXO6eE07UvOoW1C9gXAuT2XlK5BSvke4J6NzO88zwH+LC0+ArJd01seEPicsx/nAM9KKRuklJuBjVj54IBBSrlDSvm/8OdqrBnshpD499nvvP3o9L1OFKEfAmzVvhcT/cIdyEjgX0KIlUKI2eFlA6WUO8KfdwIDeyZp3Y7feSb6/b8+HKp4SgvLJdQ5CyEKgCOB/9KL7rPrvKGb7nWiCH1v4gQp5UTgDOAHQohp+kpplfUSvs1sbzlP4DHgYGACsAP4TY+mphsQQvQF/g7cKKWs0tcl8n32OO9uu9eJIvTbgGHa96HhZQmHlHJb+H8J8CJWEW6XKsKG/5f0XAq7Fb/zTNj7L6XcJaVskVK2Ak/QVmRPiHMWQiRjid0iKeXi8OKEv89e592d9zpRhH45MFoIMUIIEQIuBl7p4TR1OUKIPkKIDPUZ+DrwKda5zgpvNgt4uWdS2O34necrwHfCrTKOASq1ov8BjSsGfR7W/QbrnC8WQqQIIUYAo4GP93X6OoOwJqV9EvhcSvlbbVVC32e/8+7We93TNdBdWJN9Jlbt9VfA7T2dnm46x5FYte+rgc/UeQK5wDJgA/AmkNPTae2Cc/0rVvG1CSsm+V2/88RqhfFI+N6vBSb1dPq78JwXhs9pTTjDD9K2vz18zuuBM3o6/R043xOwwjJrgFXhvzN7wX32O+9uu9dmCASDwWBIcBIldGMwGAwGH4zQGwwGQ4JjhN5gMBgSHCP0BoPBkOAYoTcYDIYExwi9wWAwJDhG6A0GgyHB+f/JhPZO2Rzq2gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'go', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'k', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'go', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'k', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R19IJQSYoW7J"
      },
      "source": [
        "#Download the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Zed4TdFcG2iJ"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/drive/My Drive/cut_panoramic/Model', exist_ok=True)\n",
        "model.save('/content/drive/My Drive/cut_panoramic/Model/GG1_2e-4_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5eMxm1NV-oY"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/My Drive/cut_panoramic/Model/1_รอบแรก_Gender_250.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlsuaFIUVriv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}